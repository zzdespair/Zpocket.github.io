{"pages":[{"title":"","text":"申请友链须知 原则上只和技术类博客交换，但不包括含有和色情、暴力、政治敏感的网站。 不和剽窃、侵权、无诚信的网站交换，优先和具有原创作品的网站交换。 申请请提供：站点名称、站点链接、站点描述、logo或头像（不要设置防盗链）。 排名不分先后，刷新后重排，更新信息后请留言告知。 会定期清理很久很久不更新的、不符合要求的友链，不再另行通知。 本站不存储友链图片，如果友链图片换了无法更新。图片裂了的会替换成默认图，需要更换的请留言告知。 本站友链信息如下，申请友链前请先添加本站信息： 网站图标：https://removeif.github.io/images/avatar.jpg 网站名称：辣椒の酱 网站地址：https://removeif.github.io 网站简介：后端开发，技术分享 加载中，稍等几秒...","link":"/friend/index.html"},{"title":"","text":"个人简介 分享很喜欢的老罗的一段话： “每一个生命来到世间都注定改变世界，别无选择。要么变得好一点，要么变得坏一点。你如果走进社会为了生存为了什么不要脸的理由，变成了一个恶心的成年人社会中的一员，那你就把这个世界变得恶心了一点点。如果你一生刚正不阿，如果你一生耿直，没有做任何恶心的事情，没做对别人有害的事情，一辈子拼了老命勉强把自己身边的几个人照顾好了，没有成名没有发财，没有成就伟大的事业，然后耿着脖子一生正直，到了七八十岁耿着脖子去世了。你这一生是不是没有改变世界？你还是改变世界了，你把这个世界变得美好了一点点。因为世界上又多了一个好人。“ 善恶终有报,天道好轮回。不信抬头看,苍天饶过谁。无论何时何地，我们都要保持一颗积极乐观、善良感恩的心。但行好事莫问前程，永远年轻，永远热内盈眶，永远保持正能量。💪💪💪💪💪💪冲鸭！！！！ -&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;个人信息：计算机科学与技术专业从事JAVA后端开发码畜一枚坚信代码改变世界 博客信息 网站采用的Icarus主题 追求尽可能的简洁，清晰，易用。 在Icarus主题之上进行了部分修改。 更新日志：–2020.01.18：icarus3.0适配–2019.11.17：增加深色主题开关–2019.10.30：去图，精简卡片–2019.10.22：改版部分显示，优化速度–2019.10.16：文章列表加上评论数显示–2019.10.13：改版评论–2019.09.25：图片、资源接入CDN免费jsDelivr、文章加入置顶–2019.09.19：开源博客代码–2019.09.19：修改布局，拉伸布局，更宽的展示–2019.09.18：修改友链ui为一行三个，并适配移动端，暗黑模式文章增加评论链接，增加留言链接–2019.09.14：增加精简next主题–2019.09.14：利用中秋节放假，重做了首页的热门推荐、加个widget最新评论框、归档页加入文章贡献概览面板 本站推荐索引 博客主题相关 github Issue 作为博客微型数据库的应用 github page网站cdn优化加速 博客源码分享 博客换肤的一种实现方式思路 博客中gitalk最新评论的获取 博客图片上传picgo工具github图传使用 安装、部分配置icarus主题中文版 技术知识点 Java并发知识点 法律法规 法律法规数据库 中华人民共和国国旗法 中华人民共和国宪法 中华人民共和国消费者权益保护法 中华人民共和国刑事诉讼法 中华人民共和国婚姻法 中华人名共和国网络安全法 中华人民共和国劳动法 其他 网易云音乐歌单分享 计划2020计划 2019.12.31 2020-GOALS 跑两三场马拉松 2019计划 2018.12.31/21:59:00-&gt;更新于2019.12.31 2019-GOALS 购买的专业书籍至少看完一遍（并发、重构、设计模式…）-&gt; 95% 额外： 追了很多剧 总结： 有优点有缺点，没坚持下来的还是太多，追了太多剧。以后多学习，多思考！ 时间轴记录","link":"/about/index.html"},{"title":"","text":"唐艺昕 李沁 李一桐 gakki 图片搜集于互联网，侵权请留言，马上处理😊。","link":"/album/index.html"},{"title":"","text":"来而不往非礼也畅所欲言，有留必应","link":"/message/index.html"},{"title":"","text":"&nbsp;&nbsp;听听音乐 音乐播放器由mePlayer提供，布局参照网友博客所作，感谢作者的辛勤付出。更多音乐分享请查看歌单。 &nbsp;&nbsp;看看视频 ->点击以下条目开始播放视频,向下滑动查看更多","link":"/media/index.html"},{"title":"音乐歌单收藏","text":"--- 温馨提示：选择喜欢的音乐双击播放，由于版权原因部分不能播放。如果喜欢歌单收藏一下，去网易云都能播放哟！","link":"/music/index.html"},{"title":"","text":"碎碎念 tips：github登录后按时间正序查看、可点赞加❤️、本插件地址..「+99次查看」 碎碎念加载中，请稍等... $.getScript(\"/js/gitalk_self.min.js\", function () { var gitalk = new Gitalk({ clientID: '46a9f3481b46ea0129d8', clientSecret: '79c7c9cb847e141757d7864453bcbf89f0655b24', id: '666666', repo: 'issue_database', owner: 'removeif', admin: \"removeif\", createIssueManually: true, distractionFreeMode: false }); gitalk.render('comment-container1'); });","link":"/self-talking/index.html"}],"posts":[{"title":"Elasticsearch 笔记","text":"摘要 因最近项目需求，开始使用Elasticsearch。 因此遇到不少坑，和不习惯的地方，本篇文章不定期更新，主要用作笔记和记录 Elasticsearch 安装此处省略 Elasticsearch 基本使用启动 Elasticsearch输入一下指令开启服务 1sudo systemctl restart elasticsearch.service 本地环境是Mac下搭建的Homestead环境，内核信息如下 1Linux version 4.15.0-96-generic (buildd@lgw01-amd64-004) (gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04)) #97-Ubuntu SMP Wed Apr 1 03:25:46 UTC 2020 初次使用创建最简单的数据 12345curl -X PUT \"localhost:9200/customer/_doc/1?pretty\" -H 'Content-Type: application/json' -d'{ \"name\": \"John Doe\"}' Es所有Api访问方式都是Http访问，所以使用curl方式连接和传输数据 如果该请求customer尚不存在，此请求将自动创建该索引，添加ID为的新文档1，并存储该name字段并为其建立索引。 由于这是一个新文档，因此响应显示该操作的结果是创建了该文档的版本1： 返回体： 1234567891011121314{ &quot;_index&quot; : &quot;customer&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;created&quot;, &quot;_shards&quot; : { &quot;total&quot; : 2, &quot;successful&quot; : 2, &quot;failed&quot; : 0 }, &quot;_seq_no&quot; : 26, &quot;_primary_term&quot; : 4} 新文档可立即从群集中的任何节点使用。您可以使用指定文档ID的GET请求检索它： 1curl -X GET \"localhost:9200/customer/_doc/1?pretty\" 该响应表明找到了具有指定ID的文档，并显示了已索引的原始源字段。 123456789101112{ \"_index\" : \"customer\", \"_type\" : \"_doc\", \"_id\" : \"1\", \"_version\" : 1, \"_seq_no\" : 26, \"_primary_term\" : 4, \"found\" : true, \"_source\" : { \"name\": \"John Doe\" }} 批量添加文件如果您有很多要添加的文档，则可以使用批量API批量提交。使用批量处理批处理文档操作比单独提交请求要快得多，因为它可以最大程度地减少网络往返次数。 最佳批处理大小取决于许多因素：文档大小和复杂性，索引编制和搜索负载以及群集可用的资源。一个好的起点是批处理1,000至5,000个文档，总有效负载在5MB至15MB之间。从那里，您可以尝试找到最佳位置。 要将一些数据导入Elasticsearch，您可以开始搜索和分析： 下载accounts.json样本数据集。此随机生成的数据集中的文档代表具有以下信息的用户帐户： 12345678910111213{ \"account_number\": 0, \"balance\": 16623, \"firstname\": \"Bradshaw\", \"lastname\": \"Mckenzie\", \"age\": 29, \"gender\": \"F\", \"address\": \"244 Columbus Place\", \"employer\": \"Euron\", \"email\": \"bradshawmckenzie@euron.com\", \"city\": \"Hobucken\", \"state\": \"CO\"} bank使用以下_bulk请求将帐户数据添加到索引中： 123curl -H \"Content-Type: application/json\" -XPOST \"localhost:9200/bank/_bulk?pretty&amp;refresh\" --data-binary \"@accounts.json\" curl \"localhost:9200/_cat/indices?v\" 响应表明成功添加了1,000个文档。 12health status index uuid pri rep docs.count docs.deleted store.size pri.store.sizeyellow open bank l7sSYV2cQXmu6_4rJWVIww 5 1 1000 0 128.6kb 128.6kb 开始搜索将一些数据摄取到Elasticsearch索引后，您可以通过将请求发送到_search端点来对其进行搜索。要访问全套搜索功能，请使用Elasticsearch Query DSL在请求正文中指定搜索条件。您可以在请求URI中指定要搜索的索引的名称。 例如，以下请求检索bank 按帐号排序的索引中的所有文档： 12345678curl -X GET \"localhost:9200/bank/_search?pretty\" -H 'Content-Type: application/json' -d'{ \"query\": { \"match_all\": {} }, \"sort\": [ { \"account_number\": \"asc\" } ]}' 默认情况下，hits响应部分包括与搜索条件匹配的前10个文档： 123456789101112131415161718192021222324252627282930313233{ \"took\" : 63, \"timed_out\" : false, \"_shards\" : { \"total\" : 5, \"successful\" : 5, \"skipped\" : 0, \"failed\" : 0 }, \"hits\" : { \"total\" : { \"value\": 1000, \"relation\": \"eq\" }, \"max_score\" : null, \"hits\" : [ { \"_index\" : \"bank\", \"_type\" : \"_doc\", \"_id\" : \"0\", \"sort\": [0], \"_score\" : null, \"_source\" : {\"account_number\":0,\"balance\":16623,\"firstname\":\"Bradshaw\",\"lastname\":\"Mckenzie\",\"age\":29,\"gender\":\"F\",\"address\":\"244 Columbus Place\",\"employer\":\"Euron\",\"email\":\"bradshawmckenzie@euron.com\",\"city\":\"Hobucken\",\"state\":\"CO\"} }, { \"_index\" : \"bank\", \"_type\" : \"_doc\", \"_id\" : \"1\", \"sort\": [1], \"_score\" : null, \"_source\" : {\"account_number\":1,\"balance\":39225,\"firstname\":\"Amber\",\"lastname\":\"Duke\",\"age\":32,\"gender\":\"M\",\"address\":\"880 Holmes Lane\",\"employer\":\"Pyrami\",\"email\":\"amberduke@pyrami.com\",\"city\":\"Brogan\",\"state\":\"IL\"} }, ... ] }} 该响应还提供有关搜索请求的以下信息： took – Elasticsearch运行查询所需的时间（以毫秒为单位） timed_out –搜索请求是否超时 _shards –搜索了多少个分片，以及成功，失败或跳过了多少个分片。 max_score –找到的最相关文件的分数 hits.total.value -找到了多少个匹配的文档 hits.sort -文档的排序位置（不按相关性得分排序时） hits._score-文档的相关性得分（使用时不适用match_all） 每个搜索请求都是独立的：Elasticsearch不会在请求中维护任何状态信息。要翻阅搜索结果，请在您的请求中指定from和size参数。 例如，以下请求的匹配数为10到19： 12345678910curl -X GET \"localhost:9200/bank/_search?pretty\" -H 'Content-Type: application/json' -d'{ \"query\": { \"match_all\": {} }, \"sort\": [ { \"account_number\": \"asc\" } ], \"from\": 10, \"size\": 10}' 现在，您已经了解了如何提交基本的搜索请求，可以开始构建比有趣的查询match_all。 要在字段中搜索特定术语，可以使用match查询。例如，以下请求搜索该address字段以查找地址包含mill或的客户lane： 12345curl -X GET \"localhost:9200/bank/_search?pretty\" -H 'Content-Type: application/json' -d'{ \"query\": { \"match\": { \"address\": \"mill lane\" } }}' 要执行词组搜索而不是匹配单个词，请使用 match_phrase代替match。例如，以下请求仅匹配包含短语的地址mill lane： 12345curl -X GET \"localhost:9200/bank/_search?pretty\" -H 'Content-Type: application/json' -d'{ \"query\": { \"match_phrase\": { \"address\": \"mill lane\" } }}' 要构造更复杂的查询，可以使用bool查询来组合多个查询条件。您可以根据需要（必须匹配），期望（应匹配）或不期望（必须不匹配）指定条件。 例如，以下请求在bank索引中搜索属于40岁客户的帐户，但不包括居住在爱达荷州（ID）的任何人： 1234567891011121314curl -X GET \"localhost:9200/bank/_search?pretty\" -H 'Content-Type: application/json' -d'{ \"query\": { \"bool\": { \"must\": [ { \"match\": { \"age\": \"40\" } } ], \"must_not\": [ { \"match\": { \"state\": \"ID\" } } ] } }}' 布尔查询中的每个must，should和must_not元素称为查询子句。文档满足每个条款must或 should条款的标准的程度有助于文档的相关性得分。分数越高，文档就越符合您的搜索条件。默认情况下，Elasticsearch返回按这些相关性分数排名的文档。 must_not子句中的条件被视为过滤器。它影响文件是否包含在结果中，但不会影响文件的评分方式。您还可以显式指定任意过滤器，以基于结构化数据包括或排除文档。 例如，以下请求使用范围过滤器将结果限制为余额在20,000美元到30,000美元（含）之间的帐户。 1234567891011121314151617curl -X GET \"localhost:9200/bank/_search?pretty\" -H 'Content-Type: application/json' -d'{ \"query\": { \"bool\": { \"must\": { \"match_all\": {} }, \"filter\": { \"range\": { \"balance\": { \"gte\": 20000, \"lte\": 30000 } } } } }}' 使用聚合Elasticsearch聚合使您能够获取有关搜索结果的元信息，并回答诸如“德克萨斯州有多少个帐户持有人？”之类的问题。或“田纳西州的平均帐户余额是多少？” 您可以在一个请求中搜索文档，过滤命中并使用汇总分析结果。 例如，以下请求使用terms汇总将bank索引中的所有帐户按状态分组，并按降序返回帐户数量最多的十个州： 123456789101112curl -X GET \"localhost:9200/bank/_search?pretty\" -H 'Content-Type: application/json' -d'{ \"size\": 0, \"aggs\": { \"group_by_state\": { \"terms\": { \"field\": \"state.keyword\" } } }}' buckets响应中的是的值state字段中。该 doc_count节目在每个州帐户数量。例如，您可以看到ID（爱达荷州）有27个帐户。因为请求set size=0，所以响应仅包含聚合结果。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455{ \"took\": 29, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"skipped\" : 0, \"failed\": 0 }, \"hits\" : { \"total\" : { \"value\": 1000, \"relation\": \"eq\" }, \"max_score\" : null, \"hits\" : [ ] }, \"aggregations\" : { \"group_by_state\" : { \"doc_count_error_upper_bound\": 20, \"sum_other_doc_count\": 770, \"buckets\" : [ { \"key\" : \"ID\", \"doc_count\" : 27 }, { \"key\" : \"TX\", \"doc_count\" : 27 }, { \"key\" : \"AL\", \"doc_count\" : 25 }, { \"key\" : \"MD\", \"doc_count\" : 25 }, { \"key\" : \"TN\", \"doc_count\" : 23 }, { \"key\" : \"MA\", \"doc_count\" : 21 }, { \"key\" : \"NC\", \"doc_count\" : 21 }, { \"key\" : \"ND\", \"doc_count\" : 21 }, { \"key\" : \"ME\", \"doc_count\" : 20 }, { \"key\" : \"MO\", \"doc_count\" : 20 } ] } }} 您可以组合聚合以构建更复杂的数据汇总。例如，以下请求将一个avg聚合嵌套在先前的 group_by_state聚合中，以计算每个状态的平均帐户余额。 12345678910111213141516171819curl -X GET \"localhost:9200/bank/_search?pretty\" -H 'Content-Type: application/json' -d'{ \"size\": 0, \"aggs\": { \"group_by_state\": { \"terms\": { \"field\": \"state.keyword\" }, \"aggs\": { \"average_balance\": { \"avg\": { \"field\": \"balance\" } } } } }}' 您可以通过指定terms聚合内的顺序来使用嵌套聚合的结果进行排序，而不是按计数对结果进行排序： 12345678910111213141516171819202122curl -X GET \"localhost:9200/bank/_search?pretty\" -H 'Content-Type: application/json' -d'{ \"size\": 0, \"aggs\": { \"group_by_state\": { \"terms\": { \"field\": \"state.keyword\", \"order\": { \"average_balance\": \"desc\" } }, \"aggs\": { \"average_balance\": { \"avg\": { \"field\": \"balance\" } } } } }}' 除了这些基本的存储桶和指标聚合外，Elasticsearch还提供了专门的聚合，用于在多个字段上操作并分析特定类型的数据，例如日期，IP地址和地理数据。您还可以将单个聚合的结果馈送到管道聚合中，以进行进一步分析。 聚合提供的核心分析功能可启用高级功能，例如使用机器学习来检测异常。 Elasticsearch 搜索URL搜索通过查询参数提供查询。URI搜索往往更简单，最适合测试。 1curl -X GET \"localhost:9200/my-index-000001/_search?q=user.id:kimchy&amp;pretty\" 转换为DSL搜索就是 123456789curl -X GET \"localhost:9200/my-index-000001,my-index-000002/_search?pretty\" -H 'Content-Type: application/json' -d'{ \"query\": { \"match\": { \"user.id\": \"kimchy\" } }}' Request body searches (DSL搜索)通过API请求的JSON主体提供查询。这些查询是用查询DSL编写的。在日常项目开发中请求正文搜索是重中之重。 _source 过滤字段默认情况下，搜索响应中的每个_source匹配都包含document ，这是对文档建立索引时提供的整个JSON对象。如果在搜索响应中仅需要某些源字段，则可以使用源过滤来限制返回源的哪些部分。 仅使用文档源返回字段有一些限制： 该_source字段不包含多字段或 字段别名。同样，源中的字段也不包含使用copy_to映射参数复制的值。 由于_source在lucene中将_s存储为单个字段，因此即使仅需要少量字段，也必须加载和解析整个源对象。 为避免这些限制，您可以： 使用docvalue_fields 参数获取选定字段的值。当返回相当少量的支持doc值的字段（例如关键字和日期）时，这是一个不错的选择。 使用stored_fields参数获取特定存储字段的值。（使用store映射选项的字段。） 使用场景： 12345678910111213curl -X GET \"localhost:9200/_search?pretty\" -H 'Content-Type: application/json' -d'{ \"_source\": { \"includes\": [ \"obj1.*\", \"obj2.*\" ], \"excludes\": [ \"*.description\" ] }, \"query\": { \"term\": { \"user.id\": \"kimchy\" } }}' 名词 解释 _source 源过滤 若传值为false，不返回全部资源 includes 则仅返回与其模式之一匹配的源字段 excludes 从子集中排除字段 aggs 聚合聚合功能为ES注入了统计分析的血统，使用户在面对大数据提取统计指标时变得游刃有余。聚合允许我们向数据提出一些複杂的问题，虽然他的功能完全不同于搜索，但他们其实使用了相同的数据结构，这表示聚合的执行速度很快，并且就像搜索一样几乎是实时的。 聚合的两个主要的概念，分别是 桶 和 指标 桶(Buckets) : 满足特定条件的文档的集合 当聚合开始被执行，每个文档会决定符合哪个桶的条件，如果匹配到，文档将放入相应的桶并接着进行聚合操作 像是一个员工属于男性桶或者女性桶，日期2014-10-28属于十月桶，也属于2014年桶 桶可以被嵌套在其他桶里面 像是北京能放在中国桶裡，而中国桶能放在亚洲桶裡 Elasticsearch提供了很多种类型的桶，像是时间、最受欢迎的词、年龄区间、地理位置桶等等，不过他们在根本上都是通过同样的原理进行操作，也就是基于条件来划分文档，一个文档只要符合条件，就可以加入那个桶，因此一个文档可以同时加入很多桶 指标(Metrics) : 对桶内的文档进行统计计算 桶能让我们划分文档到有意义的集合， 但是最终我们需要的是对这些桶内的文档进行一些指标的计算 指标通常是简单的数学运算(像是min、max、avg、sum），而这些是通过当前桶中的文档的值来计算的，利用指标能让你计算像平均薪资、最高出售价格、95%的查询延迟这样的数据 aggs 聚合的模板 当query和aggs一起存在时，会先执行query的主查询，主查询query执行完后会搜出一批结果，而这些结果才会被拿去aggs拿去做聚合 另外要注意aggs后面会先接一层自定义的这个聚合的名字，然后才是接上要使用的聚合桶 如果有些情况不在意查询结果是什麽，而只在意aggs的结果，可以把size设为0，如此可以让返回的hits结果集是0，加快返回的速度 一个aggs裡可以有很多个聚合，每个聚合彼此间都是独立的，因此可以一个聚合拿来统计数量、一个聚合拿来分析数据、一个聚合拿来计算标准差…，让一次搜索就可以把想要做的事情一次做完 像是此例就定义了3个聚合，分别是custom_name1、custom_name2、custom_name3 aggs可以嵌套在其他的aggs裡面，而嵌套的桶能作用的文档集范围，是外层的桶所输出的结果集 1234567891011121314151617181920212223GET 127.0.0.1/mytest/doc/_search{ \"query\": { ... }, \"size\": 0, \"aggs\": { \"custom_name1\": { // aggs后面接著的是一个自定义的name \"桶\": { ... } // 再来才是接桶 }, \"custom_name2\": { // 一个aggs裡可以有很多聚合 \"桶\": { ... } }, \"custom_name3\": { \"桶\": { ..... }, \"aggs\": { // aggs可以嵌套在别的aggs裡面 \"in_name\": { // 记得使用aggs需要先自定义一个name \"桶\": { ... } // in_name的桶作用的文档是custom_name3的桶的结果 } } } }} 返回体 123456789101112131415161718192021{ \"hits\": { \"total\": 8, \"max_score\": 0, \"hits\": [] //因为size设为0，所以没有查询结果返回 }, \"aggregations\": { \"custom_name1\": { ... }, \"custom_name2\": { ... }, \"custom_name3\": { ... , \"in_name\": { .... } } } } 完整例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576GET /metric.*/_search // 指定index查询{ \"size\":0, // 返回数限定0 \"aggs\": { // 聚合开启关键字，固定格式 \"2\": { // 对这个聚合起名字 \"date_histogram\": { // 这个聚合的类型 ，这里是时间直方图聚合 \"fixed_interval\": \"1d\", // 该聚合类型内的关键字，在各个类型内有详解 \"field\": \"datetime\", \"min_doc_count\": 1, \"time_zone\": \"Asia/Shanghai\" }, \"aggs\": { ---- \"avg_grade\": { | \"avg\": { | \"field\": \"value\" | } | }, | \"max_price\": { | \"max\": { |--&gt; // 针对上面聚合后产生的文档，再次进行聚合操作 \"field\": \"value\" | } | }, | \"min_price\": { | \"min\": { | \"field\": \"value\" | } | } | } ---- } //\"3\": { } --- //\"4\": { } | --&gt; // 对文档进行其他聚合 //\"5\": { } --- }, \"_source\": { // 过滤设置 \"includes\": [ \"value\", \"datetime\" ], \"excludes\": [] }, \"query\": { // 查询 \"bool\": { \"filter\": { \"range\": { \"datetime\": { \"time_zone\": \"Asia/Shanghai\", \"format\":\"yyyy-MM-dd HH:mm:ss\", \"gte\": \"2020-07-28 19:46:08\", \"lte\": \"2020-07-31 20:46:08\" } } }, \"must\": [ { \"match\": { \"sname\": \"gwaf_monitor_srv\" } }, { \"match\": { \"mname\": \"server_monitor\" } }, { \"match\": { \"iname\": \"mem\" } } ] } }, \"sort\": [ // 排序 { \"datetime\": \"asc\" } ]} 返回： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566{ \"took\" : 6, \"timed_out\" : false, \"_shards\" : { \"total\" : 24, \"successful\" : 24, \"skipped\" : 0, \"failed\" : 0 }, \"hits\" : { \"total\" : { \"value\" : 3012, \"relation\" : \"eq\" }, \"max_score\" : null, \"hits\" : [ ] }, \"aggregations\" : { \"2\" : { \"buckets\" : [ { \"key_as_string\" : \"2020-07-29 00:00:00\", \"key\" : 1595952000000, \"doc_count\" : 1175, \"max_price\" : { \"value\" : 292276.0 }, \"min_price\" : { \"value\" : 5144.0 }, \"avg_grade\" : { \"value\" : 13365.889361702128 } }, { \"key_as_string\" : \"2020-07-30 00:00:00\", \"key\" : 1596038400000, \"doc_count\" : 1432, \"max_price\" : { \"value\" : 188092.0 }, \"min_price\" : { \"value\" : 5436.0 }, \"avg_grade\" : { \"value\" : 10735.731843575419 } }, { \"key_as_string\" : \"2020-07-31 00:00:00\", \"key\" : 1596124800000, \"doc_count\" : 405, \"max_price\" : { \"value\" : 23408.0 }, \"min_price\" : { \"value\" : 5648.0 }, \"avg_grade\" : { \"value\" : 9392.266666666666 } } ] } }} 常用桶terms 桶针对某个field的值进行分组，field有几种值就分成几组 terms桶在进行分组时，会爲此field中的每种值创建一个新的桶 要注意此 “terms桶” 和平常用在主查询query中的 “查找terms” 是不同的东西 具体实例，先插入数据 123{ \"color\": \"red\" }{ \"color\": \"green\" }{ \"color\": [\"red\", \"blue\"] } 执行搜索 1234567891011121314GET 127.0.0.1/mytest/doc/_search{ \"query\": { \"match_all\": {} }, \"size\": 0, \"aggs\": { \"my_name\": { \"terms\": { \"field\": \"color\" // 使用color来进行分组 } } }} terms聚合应该是字段类型keyword或适用于存储桶聚合的任何其他数据类型。为了与它一起使用，text您将需要启用 fielddata 结果 1234567891011121314151617181920212223{ ... \"aggregations\": { \"my_name\": { \"doc_count_error_upper_bound\": 0, \"sum_other_doc_count\": 0, \"buckets\": [ { \"key\": \"blue\", \"doc_count\": 1 }, { \"key\": \"red\", \"doc_count\": 2 //表示color为red的文档有2个，此例中就是 {\"color\": \"red\"} 和 {\"color\": [\"red\", \"blue\"]}这两个文档 }, { \"key\": \"green\", \"doc_count\": 1 } ] } }} 因为color总共有3种值，red、blue、green，所以terms桶为他们产生了3个bucket，并计算了每个bucket中符合的文档有哪些 bucket和bucket间是独立的，也就是说一个文档可以同时符合好几个bucket，像是{&quot;color&quot;: [&quot;red&quot;, &quot;blue&quot;]}就同时符合了red和blue bucket 参数 解释 例子 field 分组依据 “field”: “color” order 可根据 _count, _key 使用 asc,desc 或者聚合名词 例1 “order”: { “_count”: “asc” } min_doc_count 最小文件数 “min_doc_count”: 10 missing 将缺少参数赋予值 “missing”: “N/A” order例子 1： 12345678910111213141516171819202122232425262728GET /_search{ \"aggs\": { \"genres\": { \"terms\": { \"field\": \"genre\", \"order\": { \"max_play_count\": \"desc\" } }, \"aggs\": { \"max_play_count\": { \"max\": { \"field\": \"play_count\" } } } } }}GET /_search{ \"aggs\": { \"genres\": { \"terms\": { \"field\": \"genre\", \"order\": { \"playback_stats.max\": \"desc\" } }, \"aggs\": { \"playback_stats\": { \"stats\": { \"field\": \"play_count\" } } } } }} order其他的高阶用方法参考官方文档ES官方文档-aggs-order date_histogram 日期直方图例如，以下是一个汇总，要求在日历时间中每个月的存储分区间隔： 1234567891011121314151617181920POST /sales/_search?size=0{ \"aggs\": { \"sales_over_time\": { \"date_histogram\": { \"field\": \"date\", // 数据中字段名 \"calendar_interval\": \"month\" // 间隔时间 //\"fixed_interval\": \"30d\" 固定间隔时间 与calendar_interval同级，不可同时使用 \"format\": \"yyyy-MM-dd\" // 指定时间格式 \"time_zone\": \"Asia/Shanghai\" // 时区调整 \"offset\": \"+6h\" // 从上午六点开始分组 \"min_doc_count\": 0, // 为空的话则填充0 \"extended_bounds\": { // 需要填充0的范围 \"min\": 1533556800000, \"max\": 1533806520000 } } } }} calendar_interval 参数 解释 minute (1m) 分钟 hour (1h) 小时 day (1d) 天 week (1w) 周 month (1M) 月 quarter (1q) 季 year (1y) 年 fixed_interval 是固定间隔时间 与日历感知间隔相比，固定间隔是固定数量的SI单位，并且永远不会偏离，无论它们位于日历上的哪个位置。一秒始终由1000毫秒组成。这允许以任意多个受支持单位指定固定间隔。 但是，这意味着固定的时间间隔不能表示其他单位，例如月份，因为一个月的持续时间不是固定的数量。尝试指定日历间隔（例如月份或季度）将引发异常。 fixed_interval 参数 解释 milliseconds (ms) 毫秒 seconds (s) 定义为1000毫秒 hours (h) 所有时间都是从00分00秒开始。定义为每个60分钟（3,600,000毫秒） days (d) 所有时间都是从最早的时间开始，通常是00:00:00（午夜）。定义为24小时（86,400,000毫秒） histogram 直方图执行汇总时，将评估每个文档的价格字段并将其四舍五入到最接近的存储桶-例如，如果价格为32且存储桶大小为，5则四舍五入将产生结果30，因此文档将“落入”与密钥关联的桶30。为了使它更加正式，这里使用了舍入函数： 1bucket_key = Math.floor((value - offset) / interval) * interval + offset interval必须是正的小数，而offset必须在小数[0, interval) （小数大于或等于0且小于interval） 以下代码段根据产品的“ price间隔”对产品进行“存储桶” 50： 123456789101112131415POST /sales/_search?size=0{ \"aggs\": { \"prices\": { \"histogram\": { \"field\": \"price\", \"interval\": 50, \"extended_bounds\": { //限定范围 \"min\": 0, \"max\": 500 } } } }} 返回如下： 1234567891011121314151617181920212223242526272829{ ... \"aggregations\": { \"prices\": { \"buckets\": [ { \"key\": 0.0, \"doc_count\": 1 }, { \"key\": 50.0, \"doc_count\": 1 }, { \"key\": 100.0, \"doc_count\": 0 }, { \"key\": 150.0, \"doc_count\": 2 }, { \"key\": 200.0, \"doc_count\": 3 } ] } }} 常用指标聚合avg 平均值123456POST /exams/_search?size=0{ \"aggs\": { \"avg_grade\": { \"avg\": { \"field\": \"grade\" } } }} 12345678{ ... \"aggregations\": { \"avg_grade\": { \"value\": 75.0 } }} max 最大值123456POST /sales/_search?size=0{ \"aggs\": { \"max_price\": { \"max\": { \"field\": \"price\" } } }} 12345678{ ... \"aggregations\": { \"max_price\": { \"value\": 200.0 } }} min 最小值123456POST /sales/_search?size=0{ \"aggs\": { \"min_price\": { \"min\": { \"field\": \"price\" } } }} 12345678{ ... \"aggregations\": { \"min_price\": { \"value\": 10.0 } }} sum 总和12345678910111213POST /sales/_search?size=0{ \"query\": { \"constant_score\": { \"filter\": { \"match\": { \"type\": \"hat\" } } } }, \"aggs\": { \"hat_prices\": { \"sum\": { \"field\": \"price\" } } }} 12345678{ ... \"aggregations\": { \"hat_prices\": { \"value\": 450.0 } }} median_absolute_deviation 中位数12345678910111213141516GET reviews/_search{ \"size\": 0, \"aggs\": { \"review_average\": { \"avg\": { \"field\": \"rating\" } }, \"review_variability\": { \"median_absolute_deviation\": { \"field\": \"rating\" } } }} 1234567891011{ ... \"aggregations\": { \"review_average\": { \"value\": 3.0 }, \"review_variability\": { \"value\": 2.0 } }} Query DSL搜索es的Query DSL以_search为endpoint，主要分为叶子查询语句（Leaf Query) 和 复合查询语句 (Compound query clauses)。 叶子查询语句（Leaf Query) 用于查询某个特定的字段，如 match , term 或 range 等 其中主要包括两类：单词匹配和全文匹配: 单词匹配(Term Level Query)不对查询语句进行分词处理，直接匹配该字段的倒排索引，包括term、terms、range查询语句: term queryterm查询语句不会对查询语句进行分词处理，直接拿查询输入的文本去检索，如下是官方文档测试案例，非常清晰: 12345678GET /_search{ \"query\": { \"term\": { \"exact_value\": \"Quick Foxes!\" //如果exact_value字段类型是keyword，则有结果，若为text则无结果 } }} terms query返回在提供的字段中包含一个或多个确切术语的文档。该terms查询与term查询相同，除了可以搜索多个值。 12345678GET /_search{ \"query\": { \"terms\": { \"user.id\": [ \"kimchy\", \"elkbee\" ] } }} 同时支持文档源的查询 参数 解释 index （必需，字符串）从中获取字段值的索引名称。 id （必需，字符串）要从中获取字段值的文档的ID。 path （必需，字符串）要从中获取字段值的字段名称。Elasticsearch将这些值用作查询的搜索词。如果字段值包含嵌套的内部对象的数组，则可以使用点表示法语法访问这些对象。 routing （可选，字符串）从中获取术语值的文档的自定义路由值。如果在为文档建立索引时提供了自定义路由值，则此参数是必需的。 示例： 123456789101112GET my-index-000001/_search?pretty{ \"query\": { \"terms\": { \"color\" : { \"index\" : \"my-index-000001\", \"id\" : \"2\", \"path\" : \"color\" } } }} range query范围查询主要用于date或number类型的字段查询中，和term、terms查询一样，不进行查询时分词: 123456789101112GET /_search{ \"query\": { \"range\": { \"age\": { \"gte\": 10, \"lte\": 20, \"boost\": 2.0 } } }} 参数 解释 gt （可选）大于 gte （可选）大于或等于 lt （可选）小于 lte （可选）小于或等于 format （可选，字符串）用于转换date查询中的值的日期格式。有关有效语法，请参见format。 time_zone （可选，字符串） 用于将查询中的值转换为UTC的协调世界时（UTC）偏移量或 IANA时区date。 boost （可选，float）浮点数，用于降低或增加查询的 相关性分数。默认为1.0 在range范围查询中，es提供了一种更加简便的日期计算，now表示当前时间，时间单位y:年，M:月，d:天，H:时，m:分，s:秒，所以now-3y就表示当前时间减去3年后的时间。 123456789101112GET /_search{ \"query\": { \"range\": { \"timestamp\": { \"time_zone\": \"+01:00\", \"gte\": \"2020-01-01T00:00:00\", \"lte\": \"now\" } } }} prefix query 词项前缀查询12345GET /_search{ \"query\": { \"prefix\" : { \"user\" : \"ki\" } }} wildcard query 通配符查询123456789101112131415161718GET /_search{ \"query\": { \"wildcard\" : { \"user\" : \"ki*y\" } }}GET /_search{ \"query\": { \"wildcard\": { \"user\": { \"value\": \"ki*y\", \"boost\": 2 } } } } regexp query 正则查询1234567891011121314151617181920GET /_search{ \"query\": { \"regexp\":{ \"name.first\": \"s.*y\" } }}GET /_search{ \"query\": { \"regexp\":{ \"name.first\":{ \"value\":\"s.*y\", \"boost\":1.2 } } }} 正则语法参考：https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-regexp-query.html#regexp-syntax fuzzy query 模糊查询123456789101112131415161718192021GET /_search{ \"query\": { \"fuzzy\" : { \"user\" : \"ki\" } }}GET /_search{ \"query\": { \"fuzzy\" : { \"user\" : { \"value\": \"ki\", \"boost\": 1.0, \"fuzziness\": 2, \"prefix_length\": 0, \"max_expansions\": 100 } } }} ids 根据文档id查询123456789GET /_search{ \"query\": { \"ids\" : { \"type\" : \"_doc\", \"values\" : [\"1\", \"4\", \"100\"] } }} 全文匹配(Full Text Query)对指定的text类型的字段进行全文检索，会先对查询语句进行分词处理，例如你输入的查询文本是”我在马路边”，es在分词器的作用下就会分词为”我”、”在”、”马路”这么几个单词，然后再去匹配。 match querymatch query是最基本的基于全文检索的字段类查询语法： 12345678910GET /_search{ \"query\": { \"match\": { \"message\": { \"query\": \"this is a test\" } } }} 那么这里经过分词后的this、is、a、test各个单词之间就是默认为”或”的匹配关系，可以通过operator关键字来显式设置各个单词间的匹配关系，如下: 1234567891011GET /_search{ \"query\": { \"match\": { \"message\": { \"query\": \"this is a test\", \"operator\": \"and\" } } }} 也可以通过minimum_should_match参数来设置控制需要匹配的单词数，比如你的文档里username存的内容是”this is a java enginer”，那么通过下面的查询语句可以控制查询文本最少要匹配到”java”、”enginer”: 1234567891011GET /_search{ \"query\": { \"match\": { \"message\": { \"query\": \"java enginer\", \"minimum_should_match\": 2 } } }} 还可用max_expansions 指定模糊匹配的最大词项数，默认是50。比如：反向索引中有 100 个词项与 ucen 模糊匹配，只选用前50 个。 12345678910111213GET ftq/_search{ \"query\": { \"match\": { \"content\": { \"query\": \"ucen elatic java\", \"fuzziness\": 2, \"minimum_should_match\": 2, \"max_expansions \": 50 } } }} match_phrase querymatch_phrase也是对字段进行检索，和match的区别在于：match_query是有顺序要求的，而match是无序的。 12345678GET /_search{ \"query\": { \"match_phrase\": { \"message\": \"this is a test\" } }} 可以通过slop参数来控制单词之间的允许间隔: 1234567891011GET /_search{ \"query\": { \"match_phrase\": { \"message\": { \"query\": \"this is a test\", \"slop\": 2 } } }} multi match query如果你需要在多个字段上进行文本搜索，可用multi_match 。multi_match在 match的基础上支持对多个字段进行文本查询。 123456789GET ftq/_search{ \"query\": { \"multi_match\" : { \"query\": \"lucene java\", \"fields\": [ \"title\", \"content\" ] } }} 还可以使用*匹配多个字段 123456789GET ftq/_search{ \"query\": { \"multi_match\" : { \"query\": \"lucene java\", \"fields\": [ \"title\", \"cont*\" ] } }} query_string query可以使用query_string查询来创建复杂的搜索，其中包括通配符，跨多个字段的搜索等等。尽管用途广泛，但查询是严格的，如果查询字符串包含任何无效语法，则返回错误。 123456789GET /_search{ \"query\": { \"query_string\": { \"query\": \"(new york city) OR (big apple)\", \"default_field\": \"content\" } }} 搜索多字段 123456789GET /_search{ \"query\": { \"query_string\": { \"fields\": [ \"content\", \"name\" ], \"query\": \"this AND that\" } }} 复合查询语句 (Compound query clauses) 用于合并其他的叶查询或复合查询语句，也就是说复合语句之间可以嵌套，用来表示一个复杂的单一查询，类比mysql的where多条件查询，es的复合查询包括Constant Score Query、Bool Query、Dis Max Query、Function Score Query、Boosting Query，这里详细说一说用的比较多的Bool Query。 Bool QueryBool 查询用bool操作来组合多个查询字句为一个查询。 可用的关键字： 参数 说明 must 根据must中的条件过滤文档，返回的结果文档必须严格匹配条件，会影响相关性算分 filter 根据must中的条件过滤文档，返回的结果文档必须严格匹配条件，和must不同的是，filter不会影响相关性算分 should 根据should中的条件进行筛选，返回的结果文档应该包含should的条件，影响相关性 算分 must_not 根据must_not中的条件过滤文档，返回的结果文档必须不包含must_not条件，会影响相关性算分 123456789101112131415161718192021222324POST _search{ \"query\": { \"bool\" : { \"must\" : { \"term\" : { \"user\" : \"kimchy\" } }, \"filter\": { \"term\" : { \"tag\" : \"tech\" } }, \"must_not\" : { \"range\" : { \"age\" : { \"gte\" : 10, \"lte\" : 20 } } }, \"should\" : [ { \"term\" : { \"tag\" : \"wow\" } }, { \"term\" : { \"tag\" : \"elasticsearch\" } } ], \"minimum_should_match\" : 1, \"boost\" : 1.0 } }} 1、must、must_not、should支持数组，同时filter的查询语句，es会对其进行智能缓存，因此执行效率较高，在不需要算分的查询语句中，可以考虑使用filter替代普通的query语句; 2、查询语句同时包含must和should时，可以不满足should的条件，因为must条件优先级高于should，但是如果也满足should的条件，则会提高相关性算分; 3、可以使用minimum_should_match参数来控制应当满足条件的个数或百分比; 4、must、must_not语句里面如果包含多个条件，则各个条件间是且的关系，而should的多个条件是或的关系。 Filter和Query的异同一个查询语句究竟具有什么样的行为和得到什么结果，主要取决于它到底是处于查询上下文(Query Context) 还是过滤上下文(Filter Context)。 Query context 查询上下文这种语句在执行时既要计算文档是否匹配，还要计算文档相对于其他文档的匹配度有多高，匹配度越高，_score 分数就越高 Filter context 过滤上下文过滤上下文中的语句在执行时只关心文档是否和查询匹配，不会计算匹配度，也就是得分。 下面来看一个例子: 123456789101112131415161718192021222324252627282930313233GET /_search{ \"query\": { //参数表示整个语句是处于 query context 中 \"bool\": { //bool 和 match 语句被用在 query context 中，也就是说它们会计算每个文档的匹配度（_score) \"must\": [ { \"match\": { \"title\": \"Search\" } }, { \"match\": { \"content\": \"Elasticsearch\" } } ], \"filter\": [ //这个子查询处于 filter context 中 { \"term\": { //语句中的 term 和 range 语句用在 filter context 中，它们只起到过滤的作用，并不会计算文档的得分。 \"status\": \"published\" } }, { \"range\": { \"publish_date\": { \"gte\": \"2015-01-01\" } } } ] } }} 结论： 1 查询上下文中，查询操作不仅仅会进行查询，还会计算分值，用于确定相关度；在过滤器上下文中，查询操作仅判断是否满足查询条件 2 过滤器上下文中，查询的结果可以被缓存。 Elasticsearch Url地址说明拿以下添加内容命令举例说明 12345curl -X PUT \"localhost:9200/customer/_doc/1?pretty\" -H 'Content-Type: application/json' -d'{ \"name\": \"John Doe\"}' URL 说明 Localhost Es服务地址 /customer index名，类似Mysql中的库名 /_doc 字段类型 /1 id 索引id pretty 将返回的信息以可读的JSON形式返回。 “name”: “John Doe” 添加内容 常用URL句子 获得节集群中的节点列表 1curl 'xxx:9200/_cat/nodes?v' 检查集群健康 1curl 'xxx:9200/_cat/health?v' 列出所有的索引 1curl 'xxx:9200/_cat/indices?v' 查看ES哪些进程在消耗资源 1curl xxx:9200/_nodes/hot_threads?pretty 查看某条语句的性能分析状况 1curl xxx:9200/xxx/_search?pretty -d '{\"profile\": true, \"query\" : { \"match\" : { \"xxx\" : \"xxx\" } }}' 对某个index进行强制合并segment，提高查询效率 1curl xxx:9200/xxx/_forcemerge?pretty 节点状态查询 1curl xxx:9200/_nodes/stats?pretty 常用URL字段index操作默认之前必须携带index前缀，比如： /customer/_search URL 说明 /_search 搜索 /_aliases 获取或操作索引的别名 /_count 返回符合条件的文档数 /type 创建或操作 类型 /_mapping 创建或操作 mapping /_settings 创建或操作 设置 (number_of_shards是不可更改的) /_open 打开被关闭的索引 /_close 关闭索引 /_refresh 刷新索引（使新加内容对搜索可见） /_flush 刷新索引将变动提交到lucene索引文件中并清空elasticsearch的transaction log，与refresh的区别需要继续研究 /_optimize 优化segement，个人认为主要是对segement进行合并 /_status 获得索引的状态信息 /_segments 获得索引的segments的状态信息 /_explain 不执行实际搜索，而返回解释信息 /_analyze 不执行实际搜索，根据输入的参数进行文本分析 /index/type/id 操作指定文档 /index/type/id/_create 创建一个文档，如果该文件已经存在，则返回失败 /index/type/id/_update 更新一个文件，如果改文件不存在，则返回失败 Nodes操作 URL 说明 /_nodes/process 我主要看file descriptor 这个信息 /_nodes/process/stats 统计信息（内存、CPU能） /_nodes/jvm 获得各节点的虚拟机统计和配置信息 /_nodes/jvm/stats 更详细的虚拟机信息 /_nodes/http 获得各个节点的http信息（如ip地址） /_nodes/http/stats 获得各个节点处理http请求的统计情况 /_nodes/thread_pool 获得各种类型的线程池（elasticsearch分别对不同的操作提供不同的线程池）的配置信息 /_nodes/thread_pool/stats 获得各种类型的线程池的统计信息 以上这些操作和可以通过如下方式 12345/_nodes/${nodeId}/jvm/stats/_nodes/${nodeip}/jvm/stats/_nodes/${nodeattribute}/jvm/stats 针对指定节点的操作。 Distributed操作 URL 说明 /_cluster/nodes 获得集群中的节点列表和信息 /_cluster/health 获得集群信息 /_cluster/state 获得集群里的所有信息（集群信息、节点信息、mapping信息等） Elasticsearch 返回体说明 took – Elasticsearch运行查询所需的时间（以毫秒为单位） timed_out –搜索请求是否超时 _shards –搜索了多少个分片，以及成功，失败或跳过了多少个分片。 max_score –找到的最相关文件的分数 hits.total.value -找到了多少个匹配的文档 hits.sort -文档的排序位置（不按相关性得分排序时） hits._score-文档的相关性得分（使用时不适用match_all） Elasticsearch 基本数据类型 字符串 string 数字类型 long integer double 等 日期 date 布尔类型 boolean 二进制 binary 复杂的数据类型 数组类型 对象类型 嵌套类型 netsted 地理数据类型 专门数据类型 ipv4 完成数据类型 单词计数类型 参考文章: ES的常规指令集合 ES官方文档 ES-聚合-aggs ElasticSearch 系列文章 DSL介绍 Elastic Search之Search API(Query DSL)、字段类查询、复合查询","link":"/2020/08/06/Elasticsearch-%E5%88%9D%E6%AC%A1%E4%BD%BF%E7%94%A8/"},{"title":"PHP 安装扩展","text":"摘要 PHP作为我的目前工作的主力语言，在使用过程中经常会出现的问题，会在之后的文章总结归纳。 这次就记录一下PHP使用过程中最常见的扩展安装， 虽然简单，但是也有一些要注意的地方，作为参考。 默认在linux环境安装 解释所有命令下载扩展压缩包这里就拿mongo扩展作为实例，先到官网 下载适用于当前运行的php版本的包下载。 解压压缩包1tar -xvzf mongo-1.6.1.tgz //mongo-1.6.1.tgz 为压缩包的名称可替换对应的压缩包名字 将下载的压缩包放在服务器内，在与压缩包同一目录下执行上述语句，进行解压。 进入解压后文件1cd mongo-1.6.1 进入解压后的文件目录，一般和下载压缩包的名字一致 PHP解析1phpize 如果你的环境装有多版本的PHP，这里会默认使用当前环境的默认PHP版本进行解析，如果你要使用指定的进行解析而又不知道这个命令的位置，可以使用以下方法 12locate phpize //查询phpize文件位置find / -name phpize //如果系统没有locate方法可使用find方法 查询结果如下： 123/usr/bin/phpize //系统全局指令/usr/local/php/bin/phpize //默认php的phpize/usr/local/php7.2/bin/phpize //php7.2的phpize 现在系统为默认的PHP版本是5.6，如要使用7.2的版本进行解析，直接运行下方语句 1/usr/local/php7.2/bin/phpize 运行完之后会显示一下文字 1234Configuring for:PHP Api Version: 20131106Zend Module Api No: 20131106Zend Extension Api No: 220131226 说明了当前PHP运行的版本依赖库，这里要和phpinfo中的页面内容一致 phpize是一个运行脚本，主要作用是检测php的环境还有就是在特定的目录生成相应的configure文件,这样makeinstall之后，生成的.so文件才会自动加载到php扩展目录下面。 检测1./configure 如果之前用指定版本解析或者报错的情况下，需要添加参数 1./configure -with-php-config=/usr/local/php5.5/bin/php-config /usr/local/php5.5/bin/php-config 部分可用前面搜索phpize的方式查找到 编译和安装1make &amp;&amp; make install 修改配置文件执行以上所有命令后，你需要修改php.ini文件，在php.ini文件中添加配置，配置如下： extension=mongo.so 重启记得重启php！ 所有命令整合12345tar -xvzf xdebug-2.9.6.tgz 解压cd xdebug-2.9.6 进入目录phpize7.2 使用指定PHP版本解析sudo ./configure -with-php-config=/usr/bin/php-config7.2 使用指定PHP版本检测sudo make&amp;&amp; sudo make install 测试安装","link":"/2020/09/23/PHP%E5%AE%89%E8%A3%85%E6%89%A9%E5%B1%95/"},{"title":"PHP 多版本运行","text":"摘要 在运行旧项目时经常会出现无法兼容PHP7的情况，这就需要同时运行两个PHP版本 这篇文章就对这种情况进行总结。 基本条件安装两个版本PHP和Nginx这里通过编译安装两个不同版本的PHP，详细安装过程此处省略 服务器使用Nginx 基本概念Nginx功能nginx具有正向代理和反向代理两个很强大的功能，首先先理解什么是正向代理 正向代理 如上图，因为xxxx网站无法访问，我们需要代理server才能访问xxxx.com。 代理server对于“我们”来说，是可以感知到的（我们连接代理server）代理server对于”xxxx服务器”来说，是不可感知的(xxxx只知道有http请求过来)。 对于人来说可以感知到，但服务器感知不到的服务器，我们叫他正向代理服务器。 反向代理：通过反向代理实现负载均衡 如上图，我们访问baidu.com的时候，baidu有一个代理服务器，通过这个代理服务器，可以做负载均衡，路由到不同的server。 此代理服务器,对于“我们”来说是不可感知的(我们只能感知到访问的是百度的服务器，不知道中间还有代理服务器来做负载均衡)。 此代理服务器，对于”server1 server2 server3”是可感知的(代理服务器负载均衡路由到不同的server)对于人来说不可感知，但对于服务器来说是可以感知的，我们叫他反向代理服务器 总的来说 ：“正向”、“反向”是相对于人的感知来说的。人能感受到的代理就是正向代理，人感受不到的代理就是反向代理。 初识Nginx与Php-fpmNginx是什么 Nginx (“engine x”) 是一个高性能的HTTP和反向代理服务器，也是一个IMAP/POP3/SMTP服务器。 Php-fpm是什么 cgi、fast-cgi协议 cgi的历史 早期的webserver只处理html等静态文件，但是随着技术的发展，出现了像php等动态语言。webserver处理不了了，怎么办呢？那就交给php解释器来处理吧！交给php解释器处理很好，但是，php解释器如何与webserver进行通信呢？ 为了解决不同的语言解释器(如php、python解释器)与webserver的通信，于是出现了cgi协议。只要你按照cgi协议去编写程序，就能实现语言解释器与webwerver的通信。如php-cgi程序。 fast-cgi的改进 有了cgi协议，解决了php解释器与webserver通信的问题，webserver终于可以处理动态语言了。但是，webserver每收到一个请求，都会去fork一个cgi进程，请求结束再kill掉这个进程。这样有10000个请求，就需要fork、kill php-cgi进程10000次。 有没有发现很浪费资源？ 于是，出现了cgi的改良版本，fast-cgi。fast-cgi每次处理完请求后，不会kill掉这个进程，而是保留这个进程，使这个进程可以一次处理多个请求。这样每次就不用重新fork一个进程了，大大提高了效率。 php-fpm是什么 php-fpm即php-Fastcgi Process Manager.php-fpm是 FastCGI 的实现，并提供了进程管理的功能。进程包含 master 进程和 worker 进程两种进程。master 进程只有一个，负责监听端口，接收来自 Web Server 的请求，而 worker 进程则一般有多个(具体数量根据实际需要配置)，每个进程内部都嵌入了一个 PHP 解释器，是 PHP 代码真正执行的地方。 Nginx如何与Php-fpm结合上面我们说了，Nginx不只有处理http请求的功能，还能做反向代理。Nginx通过反向代理功能将动态请求转向后端Php-fpm。 下面我们来配置一个全新的Nginx+Php-fpm 配置nginx.conf文件进入nginx目录下，编辑 nginx.conf文件。如图，在nginx.conf最后一行，添加include文件 添加对应的server进入上面include的路径，添加一个server. 下面我们解释一下配置项的含义： 1234567891011121314151617server { listen 80; #监听80端口，接收http请求 server_name www.example.com; #就是网站地址 root /usr/local/etc/nginx/www/huxintong_admin; # 准备存放代码工程的路径 #路由到网站根目录www.example.com时候的处理 location / { index index.php; #跳转到www.example.com/index.php autoindex on; } #当请求网站下php文件的时候，反向代理到php-fpm location ~ \\.php$ { include /usr/local/etc/nginx/fastcgi.conf; #加载nginx的fastcgi模块 fastcgi_intercept_errors on; fastcgi_pass 127.0.0.1:9000; #nginx fastcgi进程监听的IP地址和端口 }} 总而言之：当我们访问www.example.com的时候，处理流程是这样的： 12345678910111213141516171819 www.example.com | | Nginx | |路由到www.example.com/index.php | |加载nginx的fast-cgi模块 | |fast-cgi监听127.0.0.1:9000地址 | |www.example.com/index.php请求到达127.0.0.1:9000 | | 等待处理... 下面我们启用php的php-fpm来处理这个请求 打开php-fpm.conf文件，我们看到如下配置： 即:php-fpm模块监听127.0.0.1:9000端口，等待请求到来去处理。 总结nginx与php-fpm的结合，完整的流程是这样的。 12345678910111213141516171819202122232425262728 www.example.com | | Nginx | |路由到www.example.com/index.php | |加载nginx的fast-cgi模块 | |fast-cgi监听127.0.0.1:9000地址 | |www.example.com/index.php请求到达127.0.0.1:9000 | |php-fpm 监听127.0.0.1:9000 | |php-fpm 接收到请求，启用worker进程处理请求 | |php-fpm 处理完请求，返回给nginx | |nginx将结果通过http返回给浏览器 同时运行多版本的PHP也是基于这个逻辑实现的 让不同版本的php监听对应的端口，通过nginx的反向代理转发到指定的端口实现 1234567891011121314graph TDA[www.example.com] --&gt;B(Nginx) B --&gt;|fast-cgi|C(127.0.0.1:9000) C --&gt;|php-fpm| D[PHP5.6]E[www.exampl2.com] --&gt;B(Nginx) B --&gt;|fast-cgi|G(127.0.0.1:9001) G --&gt;|php-fpm| H[PHP7.2] 实际命令配置PHP打开php5.6的php-fpm.conf文件修改 1listen = 127.0.0.1:9000 打开php7.2的php-fpm.conf文件修改 1listen = 127.0.0.1:9001 不同的PHP版本都需要配置，让不同版本的PHP监听不同的端口。 配置Nginx每一个项目创建一个配置文件 1234567891011121314151617server { listen 80; #监听80端口，接收http请求 server_name www.example.com; #就是网站地址 root /usr/local/etc/nginx/www/huxintong_admin; # 准备存放代码工程的路径 #路由到网站根目录www.example.com时候的处理 location / { index index.php; #跳转到www.example.com/index.php autoindex on; } #当请求网站下php文件的时候，反向代理到php-fpm location ~ \\.php$ { include /usr/local/etc/nginx/fastcgi.conf; #加载nginx的fastcgi模块 fastcgi_intercept_errors on; fastcgi_pass 127.0.0.1:9000; #nginx fastcgi进程监听的IP地址和端口 }} 1234567891011121314151617server { listen 80; #监听80端口，接收http请求 server_name www.example2.com; #就是网站地址 root /usr/local/etc/nginx/www/huxintong_admin2; # 准备存放代码工程的路径 #路由到网站根目录www.example.com时候的处理 location / { index index.php; #跳转到www.example.com/index.php autoindex on; } #当请求网站下php文件的时候，反向代理到php-fpm location ~ \\.php$ { include /usr/local/etc/nginx/fastcgi.conf; #加载nginx的fastcgi模块 fastcgi_intercept_errors on; fastcgi_pass 127.0.0.1:9001; #nginx fastcgi进程监听的IP地址和端口 }} fastcgi_pass 的配置与PHP配置对应，需要让项目使用哪个版本的PHP就去转发到哪个PHP监听的端口 重启 重启PHP 安装完两个PHP之后，最关键的点就是要在本地同时运行两个PHP 常规重启PHP的方式 1service php-fpm restart 重启指定版本PHP 先杀掉所有之前的进程再启动 1/usr/local/php5.5/sbin/php-fpm 重启nginx 1service nginx restart 通过以下命令查看是否重启成功 1ps -ef | grep php-fpm 1ps -ef | grep nginx 检查两个端口进程是否都存在 1netstat -lntup | grep 9001 1netstat -lntup | grep 9000 看到了如下显示代表配置成功 1tcp 0 0 127.0.0.1:9001 0.0.0.0:* LISTEN 29785/php-fpm: mast 1tcp 0 0 127.0.0.1:9000 0.0.0.0:* LISTEN 29788/php-fpm: mast 至此就实现了同时运行多版本PHP，不同项目使用指定PHP运行。","link":"/2020/09/23/%E5%90%8C%E6%97%B6%E8%BF%90%E8%A1%8C%E5%A4%9A%E7%89%88%E6%9C%ACPHP/"},{"title":"Hexo 初次使用记录","text":"安装安装前提，首先需要安装两个软件： Node.js 用于安装Hexo Git 用于代码提交和外网访问 详细的安装方式可自行根据自己的系统百度搜索安装方式，以下是参考网站： https://hexo.io/zh-cn/docs/ 安装 Hexo以上两个软件装完后，即可通过npm安装Hexo 1$ npm install -g hexo-cli 然后执行以下命令指定的文件下会自动创建所需要的文件 123$ hexo init &lt;folder&gt; $ cd &lt;folder&gt;$ npm install 运行完成后会出现如下文字： 1INFO Start blogging with Hexo! 恭喜你，安装完成。 新建完后，指定文件夹下会出现的文件如下 12345678.├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes 初步使用Hexo本地运行Hexo安装好后，执行以下命令: 12$ hexo g #generate 生成静态文件$ hexo s #server 启动服务器。默认情况下，访问网址为： [http://localhost:4000/](https://link.jianshu.com/?t=http://localhost:4000/) 123INFO Validating configINFO Start processingINFO Hexo is running at http://localhost:4000 . Press Ctrl+C to stop. 出现这段文字即可访问 http://localhost:4000 , 页面如下 至此，本地Hexo搭建完成 常用命令12345$ hexo n \"myblog\" # =&gt; hexo new \"myblog\"$ hexo p # =&gt; hexo publish$ hexo g # =&gt; hexo generate$ hexo s # =&gt; hexo server$ hexo d # =&gt; hexo deploy 服务器命令1234567$ hexo server # Hexo 会监视文件变动并自动更新，无须重启服务器$ hexo server -s # 静态模式$ hexo server -p 5000 # 更改端口$ hexo server -i 192.168.1.1 # 自定义 IP$ hexo clean # 清除缓存，网页正常情况下可以忽略此条命令$ hexo g # 生成静态网页$ hexo d # 开始部署 连接Hexo和GitGit SSH配置关于SSH使用SSH协议，您可以连接到远程服务器和服务并进行身份验证。使用SSH密钥，您可以连接到GitHub，而无需在每次访问时都提供用户名或密码。 检查现有的SSH密钥以下是Mac操作系统： 打开 Terminal. 输入ls -al ~/.ssh以查看是否存在现有的SSH密钥： 12$ ls -al ~/.ssh# Lists the files in your .ssh directory, if they exist 检查目录列表，以查看是否已经有公共SSH密钥。默认情况下，公共密钥的文件名是以下之一： id_rsa.pub id_ecdsa.pub id_ed25519.pub 如果您没有现有的公钥和私钥对，或者不希望使用任何可用于连接到GitHub，可以重新申请 如果您看到列出的现有公共和私有密钥对（例如id_rsa.pub和id_rsa），您希望将它们用于连接到GitHub，则可以将SSH密钥添加到ssh-agent。 生成新的SSH密钥 打开终端。 粘贴以下文本，替换为您的GitHub电子邮件地址。 1$ ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\" 使用提供的电子邮件作为标签，这将创建一个新的ssh密钥。 1&gt; Generating public/private rsa key pair. 当提示您“输入要在其中保存密钥的文件”时，请按Enter。这接受默认文件位置。 1&gt; Enter a file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter] 在提示符下，键入一个安全密码。有关更多信息，请参阅“使用SSH密钥密码短语”。 12&gt; Enter passphrase (empty for no passphrase): [Type a passphrase]&gt; Enter same passphrase again: [Type passphrase again] 将SSH密钥添加到ssh-agent在将新的SSH密钥添加到ssh-agent来管理密钥之前，您应该已经检查了现有的SSH密钥并生成了一个新的SSH密钥。将SSH密钥添加到代理时，请使用默认的macOS ssh-add命令，而不要使用macports，homebrew或其他一些外部源安装的应用程序。 在后台启动ssh-agent。 12$ eval \"$(ssh-agent -s)\"&gt; Agent pid 59566 如果您使用的是macOS Sierra 10.12.2或更高版本，则需要修改~/.ssh/config文件以将密钥自动加载到ssh-agent中并将密码短语存储在密钥链中。 首先，检查~/.ssh/config文件是否存在于默认位置。 12$ open ~/.ssh/config&gt; The file /Users/you/.ssh/config does not exist. 如果文件不存在，请创建文件。 1$ touch ~/.ssh/config 打开~/.ssh/config文件，然后修改文件，~/.ssh/id_rsa如果您没有使用默认位置和id_rsa密钥名称，则将其替换。 1234Host * AddKeysToAgent yes UseKeychain yes IdentityFile ~/.ssh/id_rsa 将您的SSH私钥添加到ssh-agent并将密码短语存储在钥匙串中。如果您使用其他名称创建密钥，或者要添加具有其他名称的现有密钥，请使用私有密钥文件的名称替换命令中的id_rsa。 1$ ssh-add -K ~/.ssh/id_rsa GitHub账户添加新的SSH密钥在将新的SSH密钥添加到GitHub帐户之前，您应该具有： 检查现有的SSH密钥 生成一个新的SSH密钥并将其添加到ssh-agent 将新的SSH密钥添加到GitHub帐户后，您可以重新配置任何本地存储库以使用SSH。有关更多信息，请参阅“将远程URL从HTTPS切换到SSH”。 注意：不再支持DSA密钥（SSH-DSS）。现有密钥将继续起作用，但是您不能将新的DSA密钥添加到GitHub帐户。 将SSH密钥复制到剪贴板。 如果SSH密钥文件的名称与示例代码的名称不同，请修改文件名以匹配当前设置。复制密钥时，请勿添加任何换行符或空格。 12$ pbcopy &lt; ~/.ssh/id_rsa.pub# Copies the contents of the id_rsa.pub file to your clipboard 提示：如果pbcopy不起作用，则可以找到隐藏的.ssh文件夹，在您喜欢的文本编辑器中打开文件，然后将其复制到剪贴板。 在任何页面的右上角，点击您的个人资料照片，然后点击设置。 在用户设置边栏中，点击SSH和GPG密钥。 单击“ 新建SSH密钥”或“ 添加SSH密钥”。 在“标题”字段中，为新密钥添加一个描述性标签。例如，如果您使用的是个人Mac，则可以将此键称为“个人MacBook Air”。 将您的密钥粘贴到“密钥”字段中。 单击添加SSH密钥。 如果出现提示，请确认您的GitHub密码。 测试SSH连接 打开终端。 输入以下内容： 12$ ssh -T git@github.com# Attempts to ssh to GitHub 您可能会看到如下警告： 123&gt; The authenticity of host 'github.com (IP ADDRESS)' can't be established.&gt; RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.&gt; Are you sure you want to continue connecting (yes/no)? 或像这样： 123&gt; The authenticity of host 'github.com (IP ADDRESS)' can't be established.&gt; RSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.&gt; Are you sure you want to continue connecting (yes/no)? 验证您看到的消息中的指纹与步骤2中的消息之一匹配，然后键入yes： 12&gt; Hi username! You've successfully authenticated, but GitHub does not&gt; provide shell access. 以上Git SSH部分全部配置完成。 Git 仓库配置首先打开github，点击New repository，创建一个新仓库，仓库名必须要遵守格式：账户名.github.io，不然接下来会有很多麻烦。并且需要勾选Initialize this repository with a README。如下图 然后项目就建成了，点击Settings，向下拉到最后有个GitHub Pages，点击Choose a theme选择一个主题。然后等一会儿，再回到GitHub Pages，会变成下面这样： 点击那个链接，就会出现自己的网页啦，效果如下： 以上Git仓库配置完毕！ Hexo 配置在安装Hexo的根目录下找到_config.yml文件，修改Deployment配置 123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git #连接方式 repository: git@github.com:zzdespair/zzdespair.github.io.git #地址 在下载Code中能看到 branch: master #选择分支 默认master 主分支 Hexo部署到git我们需要安装hexo-deployer-git插件,在bHexo的根目录下运行一下命令进行安装 1$ npm install hexo-deployer-git --save 然后输入hexo new post &quot;article title&quot;，新建一篇文章。 然后打开Hexo\\source\\_posts的目录，可以发现下面多了一个文件夹和一个.md文件，一个用来存放你的图片等数据，另一个就是你的文章文件啦。 编写完markdown文件后，根目录下输入hexo g生成静态网页，然后输入hexo s可以本地预览效果，最后输入hexo d上传到github上。这时打开你的github.io主页就能看到发布的文章啦。 参考文章- [1] Hexo官方文档 - [2] 简书-使用hexo搭建github博客 - [3] 知乎-超详细Hexo+Github博客搭建小白教程 - [4] 简书-Hexo 搭建个人博客 #01 框架的本地安装与运行 - [5] 在本地搭建Hexo博客框架，并部署到Github - [6] Connecting to GitHub with SSH","link":"/2020/08/04/hello-hexo/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2020/08/04/hello-world/"},{"title":"决策的故事-李宁和安踏","text":"摘要 有时候在正确的时候做正确的决定，是更关键的事情 生活中不缺乏机遇，你的层次越高，眼见越高，看见的机遇越多 作者：IC实验室馆长链接：https://www.zhihu.com/question/37296063/answer/1461108165来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 聊聊我一直想聊的两个品牌，安踏和李宁。 前几天，安踏市值突破2200亿港币，创下历史新高。去年面对浑水连续数轮沽空报告，股价不跌反涨。一转眼，中国第一运动品牌这个皇冠，安踏已经戴了8年。 另一边，李宁这家公司在今年迎来了自己的30岁生日。曾经的王者在经历了一段漫长的迷茫期之后，终于找回了自己的节奏，重新向王座发起冲击。 这两家体育品牌的命运一度平行，又一度交织。相爱相杀，互为表里，各自代表一类战略模式。 由于故事太长，我会从历史发展、赞助争夺和战略差异上，聊一聊这场绵延30年的中国第一运动品牌之战。 第一章：穷小子vs富二代 1984年， 洛杉矶奥运会上，一位叫做李宁的中国体操运动员，单枪匹马拿下三金两银一铜，接近中国代表团奖牌总数的1/5。 那一年，是中国代表团时隔32年重返奥运，国人热切期盼中国代表团能在奥运赛场上摘金夺银。李宁的精彩表现，振奋了全国人民，他被誉为「体操王子」，甚至可以说，李宁本人就是中国体育史上第一个个人IP。 4年后，折戟汉城奥运的李宁选择了退役，在健力宝老总李经纬的盛情邀请下，成为了李经纬的特别助理，很快，在李经纬的帮助下，李宁创立了李宁品牌。 李宁公司诞生30年前，却像一家站在风口上的创业公司一样：有一个光环笼罩的明星创业者，既没有产品也没有工厂，就得到了当时如日中天的健力宝集团1600万元的投资，还坐拥最顶级的市场资源，以及一片蓝海的运动鞋服市场。 一开局，手上就是一把王炸。 李宁豪横到什么程度呢？1990年，刚刚创立的李宁就盯上了北京亚运会火炬接力的服装赞助权。 亚运会方面狮子大开口，要了300万美元的天价赞助费，李宁当然不愿被当成冤大头，便和对方谈判： 我这个奥运冠军，最大的遗憾就是没有穿自己国家的领奖服站上领奖台。咱们国家的企业，哪个能出得起这个钱？我们已经是最有钱的了，你就卖给我们吧。 一手民族牌，一手感情牌，加上创始人本人的光环加持，还不到一岁的李宁公司，只花了250万人民币，就赞助了亚运会圣火传递指定服装、中国国家代表队参加亚运会领奖服及中外记者的指定服装。 伴随亚运圣火传递，白色李宁牌运动服出现在人们面前，李宁品牌横空出世。 1992年，李宁被选为巴塞罗那奥运会中国代表团指定领奖服装、领奖鞋，结束了中国运动员在奥运会上使用外国体育用品的历史。 连续4届奥运会，中国奥运代表团都身着李宁运动服登上领奖台。 90年代中期，在市场化的浪潮下，资历更老的青岛双星和上海飞跃不断衰落，到了1995年左右，李宁已经坐稳了中国第一体育品牌的位置。 如果说李宁是含着金汤匙出身的天之骄子，那么安踏就是从底层爬起的草根。 不知道多少同学和我一样有体会，就是我们的爸妈都喜欢把运动鞋叫做「旅游鞋」。在八九十年代，专业运动还不那么普及的时候，旅游爬山可能是最普及的全民运动之一，旅游鞋这个叫法也被传开了。 而那个年代的「旅游鞋」，有一大批都来自晋江。 晋江制鞋业，从每家每户的小作坊起步。到后来，大到外国的耐克，小到国内的双星，火炬牌，都在晋江设厂生产。 但晋江人不做销售，也没有自己的品牌，于是出现了一个很奇怪的现象：全国上下都在卖晋江鞋，唯独自己造鞋的晋江没有赚到大钱。 于是，有一群人想做出改变。 1987年，17岁的丁世忠拿了家里鞋厂的10000块钱，在当地购买了600双鞋，单枪匹马跑去了北京卖鞋。 为了把货卖到北京西单商场，他天天去拜访商场负责人，连着跑了一个月，终于打动了商场负责人。 两年的时间，丁世忠靠着一家家跑业务，为晋江鞋拿下了包括王府井商场在内，北京各大商场的柜台。 1991年，新生的李宁牌已经在全国范围内打出了名气，而丁世忠带着在北京闯荡4年赚到的20万，回到晋江开始创业办厂，安踏就此起步。 差不多同一时代，特步、361度、匹克、鸿星尔克、德尔惠等等品牌也先后成立，成为了中国体育品牌的「晋江帮」。 初生的安踏，一边像一家典型的晋江鞋企一样，老老实实做海外代工，另一边则在慢慢建立自己的销售渠道。 只是在品牌层面，安踏还名不见经传，别说李宁，甚至不如晋江老乡匹克，只能算是弟中弟。 但就是这么个弟弟品牌，早早地盯上了李宁大哥的宝座。 当渠道逐渐成熟，安踏决定向李宁发起第一次冲锋。 根据营销行业著名的定位理论，品牌应当在目标顾客心目中占有一个独特的、有价值的位置。每个品牌，都应当做出自己的差异化。 但在国产运动品牌中，李宁已经牢牢地占据了心智，安踏怎样能做出自己的差异化呢？ 安踏决定打「个性」牌。你李宁是80年代的中国体育领军人物。如今快到新世纪了，我们也需要一个全新的体育偶像。 这个偶像，安踏选择的是孔令辉。 稍微年轻一点的同学可能对孔令辉不太熟悉。作为国乒队一哥，孔令辉不仅战绩辉煌，长相也是清瘦帅气，下至少女上至阿姨，是全国女性的梦中情人。论国民度，张继科加上马龙，估计都很难和当时的孔令辉相提并论。 请孔令辉代言，就是安踏对李宁的冲锋，更确切的说，是自杀式冲锋。 当时，安踏一年的利润只有400万，而请孔令辉代言，要花掉五分之一的年利润，算上投放央视的广告费，一年的利润就花得干干净净了。 安踏上下对此意见不一，最后还是丁世忠，一句「是知道安踏的人多，还是知道孔令辉的人多？」力排众议。 安踏这一波，确实有赌的成分。但事后看来，这笔钱可能是安踏历史上性价比最高的一次押宝。 2000年悉尼奥运会，孔令辉在男单决赛中战胜瑞典「常青树」瓦尔德内尔赢得金牌，获胜后孔令辉激动地亲吻球衣上国旗的一幕成为一代人心中的经典镜头。 伴随着奥运的热潮，安踏制作的广告也登上了央视，孔令辉对着镜头，说出安踏的广告语「我选择，我喜欢」。 你仔细想想，安踏不就是拐弯抹角地在说「别选李宁」嘛。 这句耳熟能详的经典广告语，还暗藏另一个玄机。 1999年，李宁签约了当红名模瞿颖，喊出了口号：「我运动，我存在」。 安踏的「我选择，我喜欢」，正是对标李宁的广告语创作的。而且更加符合年轻人的口吻，在那个追求个性独立的时代牢牢抓住了受众的心。 更别说瞿颖作为一个娱乐明星，无论是知名度还是品牌契合度，和孔令辉都是天壤之别。 一夜之间，安踏品牌席卷全国，当年营业额从2千多万飙升到2个亿，完成了一次默默无闻到路人皆知的蜕变。 从营销角度看，李宁没做错什么，顶多是保守了一些。但疯狂的竞争对手会抓住一切你做的不够好的地方来攻击你超越你，商业世界就是这么残酷。 大品牌坐拥大量资源没错，但船大难掉头，保守是几乎每个大牌都逃不过的通病。穷小子想要打败富二代，需要的就是「赌一把」的勇气。 此时，安踏的野心已经慢慢浮现。 第二章：偷袭CBA 有了知名度做基础，安踏趁热打铁，开始捡漏李宁手上的资源。 2004年，中国职业男子篮球联赛，也就是CBA开启了新一轮的招商。 彼时的CBA，经历了1999年各队反耐克运动，以及各队自行招商时代留下的烂摊子，加上姚明赴美征战，让全国人民的目光转向了大洋彼岸的NBA。CBA的商业前景完全不被看好。 在篮协召开的招商会上，备受期待的鞋类和服装类合作伙伴，标价仅每年1000万，仍无人问津。 新赛季即将开赛，却没有装备赞助商，眼看着球员们要没有球鞋球衣上场比赛之时，CBA掌门人李元伟只好亲自带着方案，出面拜访耐克、阿迪和李宁，希望邀其入场。 当时的李宁早已把目标放在了国际市场和NBA，在CBA市场，李宁只想花点小钱，赞助个别明星球员，而不是全面和CBA合作，于是委婉地拒绝了李元伟。耐克和阿迪那里，李元伟同样吃了闭门羹。 就在这时，安踏站了出来，而且一出手就是3年6000万，比篮协的报价高了一倍。据说李元伟在安踏公司只聊了一个小时，就敲定了合作，安踏的爽快可见一斑。 为了回报仗义疏财的安踏，CBA主动将「鞋类和服装类合作伙伴」的权益升级为「CBA唯一指定运动装备」赞助商。全联盟都必须穿安踏的球衣球鞋。有个人代言的球员，必须交一笔「赎脚费」才能穿其他品牌的鞋，还得用胶布遮住品牌logo。 也就是说，李宁本打算靠签约球星在CBA保持存在感的小算盘，被安踏直接赶尽杀绝。 安踏一赞助就是8年。这8年里CBA给安踏带来了巨大的回报。从2004年到2008年，安踏的销售额，几乎每年都以翻倍的速度增长。 此外，安踏还抢了李宁的中国大学生篮球联赛CUBA的赞助。 这件事，让当年拒绝CBA的李宁几乎悔青了肠子。直到8年后，他们才用5年20亿的价格从安踏手里夺过CBA。8年，价格翻了20倍，但中国体育市场早已不是那个蓝海，李宁错过了最好的时机。 尼尔森体育发布的《2018世界足球报告》中指出，超过51%的足球爱好者会更加青睐喜爱球队品牌赞助商的产品。其实篮球也是同理，球队，球员本身就是超级IP，拿下之后可以大大增强品牌知名度和目标消费者好感度。 通过和CBA的合作，安踏褪去晋江土财主的面貌，越来越像一家正规、专业的体育品牌。 抢了CBA还不够，安踏还开始抢占李宁的低端市场。 当时的国产运动品牌存在着明显的三档市场。耐克阿迪占据最高端，几乎不涉足低价市场；李宁占据中端，跃跃欲试想要往上爬。 而在低端市场上，通过央视广告战，安踏领衔的一众晋江品牌逐渐侵蚀了李宁的市场份额。 某种程度上，安踏是一个很清楚自己几斤几两的企业。他们将主力消费人群的形象描绘为月收入5000元左右的上班族，大学生，运动爱好者，居住在三四线城市为主。 安踏的门店也迎合了这个分布。 为了战胜李宁，安踏展开了一场终端管理改革。 一方面，安踏开始引导零售商将安踏专柜改为安踏专卖店，引入严格的店铺管理规定，统一门店视觉和服务。另一方面，安踏引入狼群战术，大规模开店，甚至不惜在同一商圈里经营多家安踏专卖店，对李宁专卖店形成围剿之势。 最重要的是，安踏展开了终端回购计划，投入巨额资金将大量门店收归旗下，改为直营。这一手，成为了未来安踏超越李宁的最重要的伏笔。 顺便说一下，安踏是一个很会埋伏笔的公司。在后面，你就会看到这些伏笔会一一成为对抗李宁的利器。 产品端，安踏也研究了三四线城市的用户需求，将性价比作为品牌卖点。 举个例子，在三四线城市或者乡村，许多地方只有粗糙的水泥地球场。中国有近80%的篮球鞋消费者都是在水泥地打篮球。 耐克阿迪的主力鞋款，都只能打塑胶球场和木质室内场，打几场水泥场，鞋底就磨穿了。至于昂贵的AJ，根本不舍得穿上水泥球场。 但是安踏反其道行之，推出了以耐磨为卖点的水泥杀手等一系列球鞋。有一段时间，提到水泥，我的第一反应就是安踏。 就这样，在李宁试图下克上逆袭阿迪耐克之时，原本属于李宁的下沉市场，被安踏疯狂蚕食。五环外市场这条现金牛，成为了安踏未来多品牌战略的基础。 富二代李宁看不上的那些资源，轻易抛弃掉的地盘，穷小子安踏毫不挑食，全部纳入旗下。08年北京奥运会之前，安踏在资本层面，已经拥有和李宁掰一掰手腕的实力。 接下来要做的，就是安静等待，等一个对手犯错的机会。 而李宁没有让安踏等太久。 第三章：错误的抉择 前面讲了这么多安踏逆袭李宁的故事，李宁真的做得很差吗？ 不，恰恰相反，李宁在品牌上，几乎做到了前无古人，后无来者的地步。安踏如今不可一世，论品牌力也远远不及李宁。 李宁的强大，很大程度上得益于商业上一连串正确的抉择。 回顾早年的李宁，就像看宫斗权谋剧里的主角一样，每个决定都恰好踩在点上。 品牌创立之初，李宁就坚持不做健力宝的独资子公司，而是引入外资，独立运营。1996年，李宁接受职业经理人的建议，与健力宝公司切断关系，赎回股份。 后来，健力宝和众多国企一样，陷入了所有权争夺，在不断的官司和扯皮中，不仅品牌价值荡然无存，创始人李经纬也锒铛入狱，最终在2013年郁郁而终。 李宁这一手操作，让公司跳下了这艘快要沉没的巨轮，避免了跟健力宝一起衰落的厄运。 在公司运营上，李宁早早地劝退了亲戚朋友，自己也退出一线，将公司交到职业经理人的手上，把家族企业成功转型成为现代化的公司。最终在2004年成功上市。 在营销上，李宁放弃了娱乐营销，专注体育，而且找到了篮球这个主营品类。2002年，李宁喊出Anything is possible（一切皆有可能）的经典slogan。 顺便说一句，这句slogan不是抄袭阿迪达斯，「没有不可能」的出现要等到两年后了。 在国际化上，李宁先后赞助了法国体操队、阿根廷男篮、瑞典和西班牙奥运代表团，成为了NBA和ATP（国际男子职业网球选手联合会）的官方市场合作伙伴，签约了NBA球员达蒙·琼斯和沙克·奥尼尔，成为第一个出现在NBA赛场上的中国球鞋品牌，还在欧洲9个国家拓展了特许经销商。 最骚的是，2008年，李宁在波特兰设立了研发中心，直接把公司开到了Nike家的老巢里。 可以说李宁的目标，是打造一个属于中国的全球化运动品牌，对标耐克阿迪。它的基本盘在国内，但视野却在全球，自然没有把安踏放在眼里。 而安踏，几乎照着李宁走过的路，重新走了一遍。同样去家族化引入职业经理人，同样选择篮球作为主营品类，同样放弃了娱乐营销。 比起李宁，安踏「永不止步」的slogan晚了4年，国际化晚了2年，港股上市晚了3年。 穷小子就像是富二代的门徒，亦步亦趋。 李宁这个品牌，总给人一种天选之子的感觉。 00年代对中国体育来说，是美妙的黄金10年，申奥成功让中国体育产业发展进入了一条快车道，而李宁作为中国奥委会多年赞助商，也顺理成章，成为了民族品牌的代表。 2008年，伴随着李宁先生高举奥运圣火在空中环绕鸟巢一周，点燃北京奥运会主火炬，更是让李宁品牌价值也来到了最高点。 北京奥运会，虽然中国代表团的赞助被阿迪达斯抢走，但李宁反手就赞助了中国乒乓球队、体操队、跳水队和射击队四支夺金「梦之队」，还拿下了央视奥运服装独家赞助权，关注度一点也没落下。 第二年，李宁在中国内地销售额反超阿迪，成为了中国市场第二，本土第一名的品牌。市值也一路飚到创新高的500亿。 股市有句俗话，利好出尽，就是利空。 从历史上看，每一个王朝的衰败，强大的敌人固然是催化剂，但核心主因，一定来自内部。 北京奥运的热度并没有延续下去，反而一定程度上透支了中国消费者对体育的热情，奥运结束后，运动鞋服的消费逐渐恢复正常。 而大多数品牌没能看到这点，奥运会前，中国已经诞生了15个门店数超过3000家的体育品牌，李宁、安踏、特步、361 度、匹克在奥运会前后纷纷上市。 市场饱和伴随消费下降，产生了大量盈利能力低下的门店和大量剩余库存，整个行业进入了为期4年的寒冬，而导致这场寒冬的，就是四个字「库存危机」。 此刻李宁，在最错误的时间，做出了最错误的抉择。 2010年，意识到品牌开始老化的李宁，启动了一次极为彻底的品牌重塑运动。 这场运动史称「90后李宁」，主要的举措包括： 1、在一切皆有可能的基础上提出了新slogan：「Make the change让改变发生」 2、提出90后李宁概念，拥抱年轻人，时尚化。 3、提高价格，将重心放到一线城市与耐克阿迪正面开战 4、换掉了沿用20年的李宁logo 企业做错一个决策很正常，难的是一口气连着做错4个决策： 首先，「让改变发生」是一个英文化的表达，读起来十分拗口，和「一切皆有可能」比起来，一个天上一个地下。 其次，当时最年长的90后才20岁，还未形成完整的消费力，年轻人也更认可阿迪耐克。李宁看似拥抱了90后，其实反过来抛弃了陪着李宁长大，最死忠的70后、80后消费者。 再次，提价不代表提档次，更不代表你能和国际大牌对抗，高端品牌向下兼容容易，中端品牌向上兼容很难，李宁长期定位中端，没有提价的资本，一线没有涨起来，三四线市场彻底崩盘。 最后，在库存大量堆积的情况下换新logo，等于直接报废一批原有产品，激化库存问题。 其中尤以第四点最为致命。李宁说到底还是一个服装公司，服装行业最重要的就是低库存，高周转，才能把成本收回来。李宁的库存周转时长几乎达到安踏的2倍，庞大的库存让终端加盟商失去了进新货的动力， 我个人从那时起就很少逛李宁门店了，因为杂志上再漂亮的新款战靴，店里也买不到。 屋漏偏逢连夜雨，李宁的背运还没完。李宁在西班牙的授权生产商宣告破产，波特兰设计中心雇员流失，与美国合作伙协议终止，李宁轰轰烈烈的国际化宣告失败。 正巧也是那时开始，鞋类垂直电商开始进入中国，国际大牌的产品价格一下子被打了下来。 2011年起，李宁营收开始进入连年下滑，2011年当年亏损近20亿，此后三年持续亏损，也开始了大规模的关店。 步子迈大了，你问过蛋吗？ 回顾「90后李宁」战略，你觉得它是错误的吗？显然不是，甚至可以说，李宁及早布局转型，是相当有远见的决策。 但当正确的策略发生在错误的时间，它就是错的。 成于战略，败于战略，不作不死，令人唏嘘。 而此时，一直在等待李宁犯错的安踏，终于意识到机会来了。 穷小子奋斗了十八年，终于和富二代坐上了同一张赌桌。 下面的内容，我将从安踏的三个伏笔讲起，讲述这个10年里，在全新的消费大环境下，安踏与李宁如何在营销和战略上展开攻防，演绎出一场荡气回肠的消费战争。 第四章：体育品牌中的大众 前面我们说到李宁犯了一个战略上的错误，在不正确的时间进行品牌重塑，不仅受累于库存压力，还因此丢失了一大波基本盘，最终让安踏抓住机会，一举超越李宁。 但要注意的是，品牌重塑这个策略本身并没有问题。 李宁的野心不止于国内，服装行业本身也不是什么高门槛行业，作为不少大牌生产基地的中国，怎么就不能有属于自己的，国际体育大牌呢？ 显然当时李宁眼中的敌人是耐克、阿迪这种大佬玩家，但是凭借李宁当时的定位，无论如何是无法与两者抗衡的。在消费者眼中，李宁的品牌形象，始终低于耐克、阿迪。 这使得李宁迫切地进行品牌升级，期望在品牌价值、产品价格上对标国际巨头，以迅速追赶差距。如果我们把自己放在当时的时间节点去看，李宁的策略不无道理。 李宁在老一辈眼中的形象已然固定，要想对标耐克、阿迪，只有不破不立这一条路子。于是李宁选择放弃原有的消费群体，把赌注压在当时年轻的90后身上，希望利用几年营销，在年轻人中重塑李宁的品牌形象。 问题在于李宁还是低估了品牌重塑的难度，这个代价显然过于惨重了。这个选择可以说是一场豪赌，用多年积累的资源，赌未来的爆发。结果不仅没有拉近自己和耐克、阿迪的举例，相反被同行安踏摘了桃子。 人们对于品牌，尤其是服装品牌的固有印象是非常难以改变的，这种品牌升级的成功案例极少，相反沦为笑柄的惨案倒是挺多。 一个著名案例就是美特斯邦威。当时美特斯邦威赞助了国内雷剧鼻祖《一起来看流星雨》，企图通过这么一部偶像剧蹭一波流量，没曾想端木磊带楚雨荨去美特斯邦威买衣服成了名场面，被嘲笑至今。 当然美邦也不是没为品牌升级做过其他努力，早在《一起来看流星雨》上映前一年，美邦就开了一条名为ME&amp;CITY的「高端线」。 毕竟随着国人审美、消费的提高，服装品牌继续保持原有调性是很可能被淘汰的。 所以这些年服装品牌都在更换设计，美邦的竞争对手森马、贵人鸟都是如此。而一直佛系的真维斯，就在去年倒闭了。 同样颇具野心的安踏当然也意识到了这个问题，不过相比李宁，安踏在人们心中更是廉价的代表。李宁做不到的事，安踏更加做不到。 所以安踏选择了另一条道路：多品牌策略。 多品牌策略是指企业根据各目标市场的不同消费者诉求，分别使用不同品牌的品牌决策策略。 多个品牌能较好地定位不同利益的细分市场，强调各品牌的特点，吸引不同的消费者群体，从而占有较多的细分市场。 我在第一次消费战争中，就提过这个策略，无论是宝洁，还是联合利华，都是多品牌策略的高端玩家。 这种策略的好处是显而易见的，既然我原本的品牌形象已经固化了，那我就再开个小号进攻其他市场不就行了？ 唯一的问题在于，重新运营一个全新的品牌，是一件非常困难的事情。于是安踏使用了绝招：买。 2009年，安踏从百丽手里收购了FILA品牌在中国的商标使用权和专营权。 当时这个来自意大利的高端运动品牌还处于连年亏损中。 但安踏没有急于让这个品牌贡献业绩，而是慢慢改造它，将专业运动的部分剥离，保留时尚休闲的元素。 FILA没有辜负安踏多年的耐心培育，从2016年开始，FILA逐渐显示出在高端市场独当一面的品牌力，虽然规模只有安踏十分之一，但利润率远超母品牌。 在运动时尚的风潮下，FILA展现了极强的品牌力，迅速成为了一二线城市消费者的新宠。 如今，FILA已经代替了在三四线城市接近饱和的安踏，成为了这家公司全新的业绩增长引擎。 根据最新的数据，在疫情情况下，FILA 品牌上半年收入逆市上涨 9.4%，达到71.52 亿元，占安踏集团48.8%。 我的一位研究体育商业的朋友，甚至用「阵中最强之人」来形容FILA。 除了FILA，安踏还在去年斥资350亿收购了亚玛芬体育，而安踏2018年的营收也不过241亿，可谓蛇吞象的壮举，颇有当年请孔令辉代言的雄心。 成立于1950年的亚玛芬体育旗下有包括始祖鸟、Wilson在内的13个品牌，涵盖网球、滑雪、登山等多个体育领域。其中Wilson更是代替斯伯丁成为今年NBA官方用球。 如今的安踏，更像是体育界的大众，通过收购的方式，运用多品牌策略，让自己的体育帝国版图继续扩张。 当然，安踏在FILA上的成功，是否能复制到亚玛芬上，还需要时间来检验。 第五章：国牌之战 虽然安踏已然成为一个庞然大物，但李宁也并非吃素的。 先问个问题，你认为安踏是什么时候超越李宁的？ 2009年，安踏市值第一次超越李宁，2011年，安踏全年营收第一次超过李宁。但这都只是资本层面上。 既然聊的是第一品牌，那么安踏与李宁的交接，应该是在2012年伦敦奥运会上。 我上一期内容里提到，安踏是个喜欢留伏笔的公司。 2009年，阿迪达斯和中国奥委会的合约期满，中国奥委会开始寻找下一任合作伙伴。北京奥运会热潮后，国内对奥运的关注就开始下降了，因此很多人都不看好伦敦奥运的营销价值。 我自己推测，当年如日中天的李宁怕是飘了，也没铁了心想夺回中国代表团的赞助权。 最终，安踏战胜了李宁等一众竞争者，以6亿元的价格，拿下了中国代表团。这个价格比08北京奥运的赞助权价格缩水了一半还不止。 这笔2009年的签约，获得回报的时间正是2012年。 营销是一场关乎心智的战斗。安踏想要取代李宁，就要给受众打下思想钢印：安踏才是真国牌。 就在李宁帝国风雨飘摇之时，安踏这却代表中国登上了伦敦奥运的舞台，大势所趋，人心向背，这一手埋了四年的伏笔，可谓是趁你病要你命。 简单分析一下，李宁长期和中国代表团合作，早已奠定了民族品牌的身份，赞助多一届少一届对李宁早已无所谓。但对安踏来说，这次的签约尤为重要。 打个不恰当的比方，中国代表团的赞助权，就如同传国玉玺一样。只有赞助过中国代表团，自称中国第一运动品牌，才符合道统。 这个权益，从1992年开始，李宁就没让别家染指过。唯一的例外是北京奥运败给阿迪达斯，但那毕竟是外国品牌，血统上就不是自家人。 但此时的安踏兵强马壮，在资本市场已经碾压李宁，再加上拿下中国代表团的赞助权，毫无争议地完成了国牌称号的交接。 尽管2012年伦敦奥运，并没有带来符合投入的回报，但安踏早已经不在乎一次赞助的得失。王朝更迭，安踏已经获得了他想要的一切。 穷小子上位以后，并没有被胜利冲昏头脑，依然视李宁为顽固的对手。 前面的内容，我们提到安踏很早就展开了终端回购计划，投入巨额资金将大量门店收归旗下，改为直营。 安踏的直营模式，比依赖经销商的李宁模式更灵活，对市场变化和消费者诉求更敏感，也就不容易积压库存。 凭借这一手伏笔，安踏率先从席卷行业的库存危机里走了出来，此时荷包满满的安踏，有底气和李宁正面打一场营销战了。 先出手的，是在伦敦奥运上被安踏偷了老家，颜面无光的李宁。 2012年，为了找回市场存在感，也为了解决品牌危机，李宁豪掷5年20亿，从安踏手中夺过了CBA官方战略合作伙伴的赞助权。又砸下10年1亿美元签约NBA球星德韦恩·韦德。 此时的安踏已经比李宁更豪横，尔要战，便战。 2013年，安踏反手就续费了中国奥委会，拿下了里约奥运的赞助权。 同一年，李宁不甘示弱，把被安踏夺走了11年的CUBA重新抢了回来。 安踏表示：你拿去吧，反正我也不是特别想要。第二年，安踏拿下了曾一度属于李宁的NBA官方市场合作伙伴。 下一年，安踏又签下了NBA球星克莱·汤普森。签约4个月后，汤普森就以核心之一身份拿下NBA总冠军，替安踏好好地出了一次风头。之后「汤神模式」、「要疯」系列广告片，也成为了安踏营销的里程碑。 更讽刺的是，李宁先生本人的老东家中国体操队，在2014年也被安踏花了5000万抢走。 这一波已经不是偷家了，简直就是大摇大摆走到你家水晶泉水里发射人民币。 把钱全花在了篮球等核心项目的李宁，再也无力和安踏竞价。 据内部人士透露，李宁公司甚至通过体操中心和安踏进行沟通，表示可以让出蹦床和艺术体操，但希望能留下体操队的权益。不过在商言商，被安踏一口回绝。 李宁低到尘埃里，落难凤凰不如鸡啊。 但商业世界里，竞争就是如此残酷，你的任何失误，都会成为对手蚕食你的契机。两家公司市值相差最多的时候，安踏一年能赚李宁两倍的钱，市值抵得上8个李宁。 从品牌层面来说，体育品牌的营销从来就不仅是打广告这么简单。 一次分量十足的代言，就能让品牌弯道超车，知名度提升几个档次。一次声势浩大的赞助，就能让品牌确立自己的江湖地位。 正如1984年，濒临倒闭的Nike，用一份近乎赌命的大合同，把前途放在了初出茅庐的乔丹身上，结果一把翻盘，最终在篮球领域，把曾经的行业老大阿迪达斯踩在了脚下。 而如今日薄西山的阿迪达斯，在足球领域依然有着不输耐克的存在感，原因就是它少而精的赞助策略，拿下了皇马、拜仁、曼联、阿森纳、尤文图斯等顶级俱乐部，让阿迪依旧维持着顶级足球品牌的尊严。 安踏做的也是同样的事情，从孔令辉到CBA再到奥运会和NBA，安踏用不断升级的赞助和代言，一步步确立了如今的地位。 第六章：新的战场 安踏和李宁不断升级加码的竞争，背后是老牌帝国阿迪逐渐掉队。 从90年代起，阿迪和耐克两大巨头就一直齐头并进，你收购一个匡威，我就买下一个锐步，针锋相对互不相让。 但2010年开始，阿迪陷入了停滞不前，而耐克的一波爆发式增长，让这个乱世从双雄并立，立刻成为了一超多强的军阀混战。 到2014年，耐克在美国运动服装市场的市场占有率，达到了阿迪的5倍多。 阿迪掉队了，意味着每个品牌都有了上位的机会。 第一个发难的是UnderArmour，这个从健身服这个细分领域起家的品牌，销售额增长连续26个季度超过20%，终于在2014年销售额超过阿迪，坐上了行业的第二把交椅。 但好景不长，旗下代言人史蒂芬·库里之后在NBA总决赛的败北，让这个异军突起的品牌的的缺点一下子暴露了：在运动鞋品类布局单薄。加上设计感实在太差，UnderArmour的时代很快就过去了。 另一个来自细分领域起家的挑战者，主营瑜伽裤的lululemon。今年年初疫情期间，lululemon逆市增长，股价一度接近400亿美元，直逼耐克。 除此之外，Vans和耐克旗下的AirJordan也曾经在部分市场和部分主要品类上超越过阿迪达斯。 可以说，整个体育品牌市场都打成了一锅粥了，遍地是小王，短暂又辉煌。就连耐克这个大王的钓鱼台都几次险些翻车。 阿迪达斯可能是过去十年最惨的行业老二，明明长着一张老二的脸，却总是坐在老三的位置。 但如果从另一个侧面看，众多品牌来来去去，崛起又衰落，谁都没能长期地取代阿迪达斯，挑战耐克。 虽然细分领域品牌的崛起是大势所趋，但像lululemon、UnderArmour这样的品牌，只有单一品类。靠着爆款异军突起容易，想要建立帝国，却是几乎不可能的。 只有一条腿的品牌，也许能跳得高，但是绝对站不稳。 能取代帝国的，只有另一个帝国，在我看来，过去十年，真正有机会取代阿迪达斯的，只有李宁和安踏这两个中国品牌。 因为这两个品牌，涵盖了鞋类和服装，涵盖了各种主流运动品类，且具备了足够的规模。 简单说，李宁和安踏长着一张帝国的脸。 2019年，安踏的市值一度达到过2104亿港元，大幅超过阿迪达斯，位居世界第二，就很能说明问题。 从这个角度，再来理解李宁和安踏的战争，就有了一层更深的涵义。 中国人有品牌情结，创造一个属于中国的世界一流品牌，不仅是一代创业家的梦想，也是许多国人的梦想。 反正都要有一个来自中国的顶级品牌，为什么不能是我呢？ 故事回到李宁。 这家公司正忙于收拾「90后李宁」战略失误造成的烂摊子，完全无力对抗步步紧逼的安踏。国际战略失败后，李宁回缩到国内市场，才发现自己在销售渠道的「内功」上，也远远不及安踏。 狂澜既倒，大厦将倾，这是李宁的至暗时刻，甚至更换了两任CEO都不见成效。 有媒体采访到李宁员工说：「碰到这种状况，如果不是李宁，早就死了不知多少次了」。 终于，2014年到了，这是李宁的幸运年。 这一年，李宁本人决定重新出山执掌公司。在他复出的第一年，李宁也终于扭亏为盈，再次走上正轨。 更重要的变化，发生在外部。 2014年开始，运动时尚化的新风潮席卷了整个行业。 2014年，阿迪达斯旗下休闲款单品「小白鞋」Stan Smith被时尚圈带火，成为了明星潮人们人脚一双的时尚单品。 2015年更是疯狂的一年，阿迪达斯旗下鞋款NMD发售，引发无数鞋迷和潮流爱好者抢购。 虽然只是普普通通的一双跑鞋，阿迪达斯却邀请了陈冠希、陈奕迅、余文乐等艺人潮人抢先上脚带货。加上限量发售，一下子将这双鞋炒火了。 另一边，阿迪达斯之前重金从耐克手里抢来了「侃爷」坎耶·韦斯特，2015年，侃爷和阿迪合作的第一款鞋adidas Yeezy Boost 750 OG「Light Grey」发售，从此椰子成了全世界潮流爱好者的圣物。 耐克的AirJordan系列也在这场运动品牌时尚化的大浪潮中成为了受益者，各种联名合作将AJ从一个高端运动鞋品牌改造成了一个顶级潮流品牌。 这场风潮席卷的不只是运动品牌和潮流圈，传统时尚圈也没能置身其外。 巴黎世家的老爹鞋，Guuci各类运动风单品，LV开始和潮牌玩联名。可以说整个服装行业都看到了一波新的机会。 李宁找到了它的救命稻草。 谁也没想到，李宁的逆袭，没有发生在赛场上，而是在2018年初的纽约时装周。 在李宁举办的大秀上，中国李宁的logo伴随着时尚的设计，引爆了社交网络，向全世界宣告，这个品牌已经脱胎换骨了。 也许这是商业之神和李宁开的一个不大不小的玩笑。 曾经在国内品牌中，论设计，论中国风，论品牌底蕴，几乎没有能和李宁抗衡的。 经典的「飞甲」、「年轮」、「钟馗」球鞋融入了中国风。 「驭帅」系列、「韦德之道」系列至今还是中国历史上最成功的两大系列球鞋。「弓」和「弧」等各种科技也被运用到跑鞋、球鞋等产品上。 可以说，李宁用品牌底蕴和美学功底，把自己的产品和晋江系一众「旅游鞋」区别了开来。 高端品牌，卖的就是文化附加值。耐克励志广告，阿迪时尚气息，都是在为品牌附加值。民族设计和历史底蕴，是李宁特有的文化附加值，是李宁冲击高端的突破口，但「90后李宁」为了讨好新一代，过于激进，以至于自废武功。 可能就连管理层自己也没有想到，8年前他们削尖了脑袋想挤进年轻人的世界而不得，如今却是当年自己弃之如敝屣的本土元素和复古底蕴，让自己完成了年轻化，而且一举走向高端。 历史的进程总是不可捉摸。 但如今强势归来的李宁，发现横亘在它面前的早已不是单打独斗的穷小子，而是坐拥一个2200亿市值的体育品牌帝国。 这已经是这十年来，双方最为势均力敌的瞬间了。 我们又终于可以看到两个属于中国的顶尖品牌，站在差不多的起跑线上，为了争夺市场各出奇招，在产品上不断迭代。 因为有了竞争和悬念，体育才变得如此激动人心，而也正是因为有了品牌之间的竞争，才有了市场的进化。也许安踏和李宁的竞争，会给整个体育行业带来又一个黄金时代。 这场充满悬念的消费战争，也许才刚刚开始。 参考资料： 《李宁，三十而已》-懒熊体育 《安踏，永不止步》-王新磊 《“90后”李宁打造出国际化品牌—变革与创新之痛》-新浪教育 《安踏闪耀CBA赛场 成为运动装备类唯一合作伙伴》-搜狐体育 《李宁：二十八年的兴衰之路》-广发证券 《李宁公司成长史：一切皆有可能》-馒头 转载-知乎","link":"/2020/09/10/%E5%86%B3%E7%AD%96%E7%9A%84%E6%95%85%E4%BA%8B-%E6%9D%8E%E5%AE%81%E5%92%8C%E5%AE%89%E8%B8%8F/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","link":"/tags/Elasticsearch/"},{"name":"PHP","slug":"PHP","link":"/tags/PHP/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Blog","slug":"Blog","link":"/tags/Blog/"},{"name":"决策","slug":"决策","link":"/tags/%E5%86%B3%E7%AD%96/"}],"categories":[]}